---
title: 科研笔记：CAT 改进方向
date: 2022-06-28
categories: [科研]
tags: [论文笔记, 持续学习]
img_path: /assets/img/
math: true
---


## 论文信息 

### [Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks](https://proceedings.neurips.cc/paper/2020/file/d7488039246a405baf6a7cbc3613a56f-Paper.pdf)


- 会议：NIPS 2020
- 作者：
  - [Zixuan Ke](https://underline.io/speakers/97701-zixuan-ke)：伊利诺伊大学芝加哥分校，博士生，后者的学生。
  - [Bing Liu](https://www.cs.uic.edu/~liub/)：伊利诺伊大学芝加哥分校，教授。他是《终身机器学习》的作者，我有系列[读书笔记](https://pengxiang-wang.github.io/tags/终身机器学习/)。
  - [Xingchang Huang](https://people.mpi-inf.mpg.de/~xhuang/)：苏黎世联邦理工大学，博士生。
- 内容：提出了一个持续学习模型。它不只关注不相似任务的灾难性遗忘，还关注相似任务的知识迁移。


--------------

# CAT 改进

## 一、质疑 if...else... 判断任务相似度的模式

1. if...else...的方式肯定不好，是非黑即白的。它在拿自己的判断为后面的一切做担保，万一判断错误，全盘皆输。
2. if...else...判断中，断言了是否一个任务与前面的任务是否相似。但是后面有很多指标能反映相似程度，如学到 mask 的重合程度。if...else...的断言可能与 mask 重合程度反映的相似程度不一致！这是一个矛盾。

**解决方法**：

1. 修正：就是遇到矛盾时选择推翻之前的断言，有点多此一举；
2. 推倒重来：就是干脆不用之前那种比较判断，直接换一个指标作为相似度标准，例如 mask 重合程度。可能的做法：都先统一只训练 KB + TM，观察 mask 重合程度，如果大于某个阈值再去训练 KTA。

## 二、质疑比较两模型效果判断相似度的公平性

即使 if...else... 的模式合理，文章判断相似度的方法也只是单纯比较两个模型效果大小：迁移模型、参考模型。

我的感觉是，肯定是自己家训出来的（参考模型）效果好的可能性大一些，因为毕竟迁移模型用的是其他任务的知识。单纯地比较效果数值大小公平吗？这样天平会不会更向参考模型好——即不迁移知识上倾斜？

作者有无 “有KTA这部分，但故意不用” 的嫌疑？需要看他的实验：

- 看在文章机制下相似/不相似的比例是否平衡，统计一下；
- 如果比例无严重不平衡，比例与效果有无关系（例如 KTA 用的越多，效果越差，会说明问题）；
- 三是手动地调整比例，修改 if...else... 语句（极端情况：只相似或不相似），观察规律；

**解决方法**：修改判断相似度的方法，例如简单地引入一个天平系数的参数，调控天平平衡的条件，使其公平。这个参数可以是：

- 超参数，在训练前固定下来，常数或者与当前任务数相关的量；
- 可学习的参数。

## 三、（小问题）测试与训练一致

测试时，如果 $$t$$ 与之前有的任务相似，文章的做法是 $$x$$ 通过 KB 在 $$\tau_{sim}$$ 任务上的 mask 得到一系列特征 $$h_{mask}^{(i_{sim})}$$，让它们过 KTA 和后面的分类头，得到分类结果，没有用到 $$h_{mask}^{(t)}$$ 过 KB 后面的分类头。但在训练时，无论 $$t$$ 与之前有无相似，都会训练 $$t$$ 的任务 mask。

如果 $$t$$ 与之前有的任务相似，可不可以也用上 $$h_{mask}^{(t)}$$？

## 四、预留的 Mask 空间不够用

# 应用到 IIRC 场景中

文章的思路可以模仿到 IIRC 场景中。

IIRC 为任务之间引入了层级关系。层级关系其实是相似关系的一种特殊情况，大方向是：将任务相似度的概念细到层级性的概念，将文章判断相似度的方法细化为判断父子关系的方法。模型方面，KB + TM 的机制可以完美用上，而 KTA 需要作一些修改，以适应层级关系。

问题：和相似关系不一样的地方是，每一个子类只能有一个父类。