---
title: 学习笔记：持续学习
date: 2022-07-27
categories: [科研]
tags: [学习笔记, 持续学习]
img_path: /assets/img/
math: true
---

目前我的研究方向是持续学习。本文汇总了持续学习的基础知识体系，可以看作一篇综述吧，希望这篇笔记能带你进入我的研究领域。本文涉及的方法都是我觉得有代表性的，只介绍思想，不会非常详细地讲细节。


# 相关概念

相关概念已经在[《终身机器学习》读书笔记](https://pengxiang-wang.github.io/tags/终身机器学习/)的第一、二章中详细介绍过，这里只是简单概括一下。

**持续学习**（Continual Learning, CL）是多个任务的机器学习的一种学习范式。持续学习又称**终身学习**（Lifelong Learning），终身学习于很早提出，进入深度学习时代后研究者逐渐改叫持续学习；还有人把持续学习叫做**增量学习**（Incremental Learning）。持续学习从大面来说是：多个任务数据**依次**交付给系统学习（每次**只有当前任务数据**），使得最终系统能够胜任**所有**任务。“依次”和“所有”是持续学习的核心，缺一者就与只有单任务的机器学习无差别了：

- 缺“依次”：每次系统能用之前所有任务数据学习，则最后一个任务时就能学习所有任务，就不“持续”了。在实际场景中，旧数据主要是由于存储限制或隐私保护等原因而不可用的。
- 缺“所有”：若不要求在所有任务上表现都好（例：只要求当前任务），则就是当前任务的单任务的机器学习。

持续学习与其他学习范式的主要区别：

- 在线学习：数据都是同一个任务来的，一定是独立同分布的；持续学习划出多个任务，数据不一定（不是一定不，但通常不是）是独立同分布的。且它的研究重点是“在线”与“离线”的区别；
- 迁移学习：重点关注的是“迁移”——如何利用旧任务的学习成果帮助新任务的学习；
- 多任务学习：数据是一次给完的，强调同时学习多个任务；
- 元学习：“学会学习”的角度更高，不只关注如何解决当前所有任务，还试图提取学习经验，泛化到新的任务。


# 持续学习关心的问题

## 灾难性遗忘

上面已经说过，在持续学习中，使用新任务数据训练模型使其在该新任务上效果好，是很容易做到的，只需应用成熟的单任务机器学习的算法即可；相反，很多时候学习新任务后，模型在旧任务上的效果会变差，这就是**灾难性遗忘**（Catastrophic Forgetting, CF），也是持续学习关心的核心问题。解决这一问题的方法是引入**防遗忘机制**，使模型保持旧任务上的效果。

从哲学上来说，假设模型的学习能力是固定的，模型在新任务上效果好，则在旧任务上效果会变差；反之，模型保持了旧任务上的效果，则在新任务上效果就不会好。前者是模型学习新知识的能力，称为**可塑性**（plasticity）；后者是旧知识的记忆能力，称为**稳定性**（stability）。可塑性与稳定性是内在相互矛盾的，术语叫**可塑性-稳定性困境**（Stability-Plasticity Dilemma），这是机器学习的一个天然的哲学约束，类似于 “没有免费午餐定理”。持续学习的目标是在所有任务上表现都好，即同时追求可塑性和稳定性；但这个困境说明了实现这一目标没有捷径，持续学习场景不是伪命题，并不是无脑加防遗忘机制、加强防遗忘的力度（例如调大防遗忘正则项超参数）就可以了，必须切实地提高模型的真本领。

## 后向迁移

前和后的问题。

## 前向迁移

前向迁移比后向迁移还要厉害。

## 模型容量（capacity）记忆问题（memory cost）


学习任务的类型和数量没有预定义。

实现这一目标的一种简单方式是为每个任务都单独学习一个模型，但这样做导致模型大小成线型地增加，也是不被持续学习允许的。




## 分类问题

持续学习也分监督学习、无监督学习等，也有判别模型、生成模型。目前大家研究最多的是监督学习，且更多地关心分类问题，本文只讨论分类问题。


在分类问题中，研究者公认的持续学习场景有以下几个（主要是前两个）：

- **类别增量学习**（Class Incremental Learning, CIL）：每个任务包含若干不重复的类别；
- **任务增量学习**（Task Incremental Learning, TIL）：每个任务对数据的类别等信息不作要求，但数据中包含“属于哪个任务”这个信息；
- **领域增量学习**（Domain Incremental Learning）：每个任务包含的类别相同，但背后的领域不同。

## 形式化定义

下面给出形式化定义。设有任务 $$\tau_1,\tau_2,\cdots$$，每个任务的数据集为 $$\mathcal{D}^{(t)}, t=1,2,\cdots$$，其中 $$\mathbf{D}^{(t)} =\{(\mathbf{x}_i,y_i)\}_{i=1}^{N_t} \in (\mathcal{X}^{(t)},\mathcal{Y}^{(t)})$$。对模型 $$f^{(t)}$$，每个时刻 $$t$$ 允许利用 $$D^{(t)}$$ 将 $$f^{(t-1)}$$ 更新 $$f^{(t)}$$，希望 $$f^{(t)}$$ 能完成目前涉及到的所有分类任务，即输入 $$\mathbf{x} \in \mathcal{X}^{(1)}\cup\cdots\cup\mathcal{X}^{(t)}$$，输出所有涉及到的类别 $$\hat{y} \in \mathcal{Y}^{(1)}\cup \cdots \cup \mathcal{Y}^{(t)}$$。

- 类别增量学习：$$\mathcal{Y}^{(t)}$$ 之间互不相交。可以设 $$\mathcal{Y}_1 = \{C_1,\cdots,C_{k_1}\}, \mathcal{Y}_2 = \{C_{k_1 + 1}, \cdots, C_{k_2}\}, \cdots$$；
- 任务增量学习：知道了输入的任务 ID $$t_{\mathbf{x}}$$（主要是对测试数据说的，训练数据天生是知道任务 ID 的），即目标简化为输入 $$\mathbf{x}\in \mathcal{X}^{(t_\mathbf{x})}$$，输出 $$\hat{y} \in \mathcal{Y}^{(t_\mathbf{x})}$$；
- 领域增量学习：$$\mathcal{Y}^{(1)}=\cdots=\mathcal{Y}^{(t)}$$，但强调 $$\mathcal{X}^{(1)},\cdots,\mathcal{X}^{(t)}$$ 的不同。

很明显，CIL 场景是比 TIL 场景要困难的。另外，在实践中为了指标衡量的方便，总任务数是固定的 $$T$$ 个，以上 $$t=1,\cdots,T$$，但是持续学习算法在任何时刻都禁止使用 $$T$$ 这个信息。

> 类别增量学习每个任务至少包含 2 个类。每次只有 1 个类的话，没有该类的负样本，也无从学习。
{: .prompt-warning }

## Baseline：多头模型

由于每个任务来的类不一样，类往往是越来越多的（这种现象在 CIL 是必然，TIL 不一定）。而且系统不知道未来有哪些类，无法在一开始就把所有类包括进来，构造出输出头固定的分类器；只能每当出现新类，临时加入该类的输出头。所谓的**多头模型**是指模型的主要部分由各任务共用，但输出端不固定，随时会引入新的输出头。因此模型参数会包含共享参数和任务独有（task-specific）的参数两部分，后者的比例应该是非常小的，所以即使它的数量线性增长问题也不大，是允许的。在持续学习分类问题中，不管是 CIL 还是 TIL，一般默认多头模型。

下图是持续学习最基本的 **baseline**（最简单的模型），是多头模型：

![](continual_learning_baseline.pdf)

这个 baseline 采用最简单的学习方式，并不是每个新任务都从头开始训练，而是用上一个任务的训练结果作为下一个任务的初始化。具体来说，上图模型参数分为网络共享权重 $$\mathbf{w}_0$$ 和每个类别独有的权重 $$\mathbf{w}_1,\mathbf{w}_2,\cdots$$。每遇到新类别都会引入新的 $$w_i$$，都作（随机）初始化。$$\mathbf{w}_0$$ 在算法的最开始（随机）初始化，且在每个时刻 $$\mathbf{w}^{(t)}$$ 都会用 $$\mathbf{w}^{(t-1)}$$ 初始化。

这个 baseline 在持续学习论文里习惯叫做**微调（fine-tuning）**，因为直接拿上一个任务初始化的方式有微调上一个任务的意思。直观上看这种方式有覆盖上个任务成果的感觉，很容易产生灾难性遗忘。尽管有每个任务特定的参数能防止遗忘，但它们占的比例太小，起的作用是远远不够的。因此这个模型可以认为**没有任何防遗忘机制**，是一个白板模型，大家研究的持续学习模型都是在其基础上引入自己的防遗忘机制的。



## 数据集与指标

持续学习分类问题的常用**数据集**是通过机器学习的标准数据集划分、构造出来的。标准数据集指常用的 MNIST、CIFAR-10、CIFAR-100、ImageNet 等。划分方式主要有两种：

- 分割（Split）：按照类别划分数据集为任务。可以用于类别增量场景；
- 置换（Permute）：每个类别各按照一定顺序抽取一部分组成任务，每个任务都包含原数据集的全部类别。可以用于任务增量场景。注意不是随机抽取，为了让任务之间体现出分布上的差异。

以 MNIST 为例，可以构造 Split MNIST、Permuted MNIST 两种数据集。Split MNIST 划分成（以 5 个任务为例）0v1, 2v3, 4v5, 6v7, 8v9；Permuted MNIST 每构造一个任务时就按相同方式随机打乱各图片像素的顺序。

持续学习的主要目标是让模型在所有任务上表现都好，因此持续学习的**指标**首先是**各任务平均指标**，其次关注其他关心问题上的表现，如**后向迁移能力**、**前向迁移能力**。这些指标都是持续学习过程训练的各模型在各任务上的单个指标计算出来的（参考：Gradient Episodic Memory for Continual Learning）。记 $$R_{\tau,t}$$ 表示时刻 $$\tau$$ 训出的模型在第 $$t$$ 个任务上的指标（例，对分类问题是准确率），注意每个任务都有自己的测试集 $$\mathcal{D}^{(t)}_{test}$$，$$R_{\tau,t}$$ 是用 $$\mathcal{D}^{(t)}_{test}$$ 做测试的。有以下指标：

- 各任务平均指标：$$ ACC = \frac1T \sum_{t=1}^T R_{T,t}$$，即**最后**得到的模型在所有任务上的平均表现；
- 平均后向迁移能力：$$ BWT = \frac1{T-1} \sum_{t=1}^{T-1} (R_{T,t}- R_{t,t}) $$，即任务刚开始学（$$t$$ 时刻）与学到最后（$$T$$ 时刻）效果之差，对所有非最后一个任务取平均。这个指标只衡量了最后一个任务的后向迁移情况。
- 平均前向迁移能力：$$ FWT = \frac1{T-1} \sum_{t=1}^{T-1} (R_{t-1,t} - \bar{b}_t)$$。$$\bar{b}_t$$ 是随机初始化并用 $$\mathcal{D}_t$$ 训练的模型效果（多次实验取平均），有点 $$R_{0,t}$$ 的意思，但不太一样。指标表示到在任务刚开始学但还没有学（$$t-1$$ 时刻）期间累积的知识（比较的对象是不使用 $$\mathcal{D}_1,\cdots, \mathcal{D}_{t-1}$$ 前向迁移的知识、而只使用 $$\mathcal{D}_t$$ 自己知识的结果 $$\bar{b}_t$$），对所有非第一个任务取平均。

第一个指标的定义方式是公认的，后两者可能还有待探索。举个例子，FWT 中的 $$R_{t-1,t}$$ 在 CIL 场景下是无法计算的，因为在 $$t-1$$ 时刻压根就没有 $$t$$ 时刻新出现的类别，FWT 需要另外定义。

> 以上指标都是以任务为单位作算数平均计算出来的，通常要求任务划分得比较均衡（事实上多数数据集是这样的，例如 CIL 每个任务的类数量相等），否则最好根据任务规模/难易加权平均。还有的指标转而以类别为单位算平均。
{: .prompt-tips }


# 防遗忘机制概论

目前学界普遍承认防遗忘机制可以分成三大类：重演数据法、正则化法、网络结构法。

## 重演数据法

重演（replay）数据

要求 $$\mathcal{M}$$ 固定容量。

知识蒸馏技术与CL的关系

经典方法：iCaRL

Rehearsal
    \item Generative (Pseudo Rehearsal)


## 防遗忘正则项

LwF


经典方法：EWC

## 防遗忘的网络结构
Parameter isolation methods


# Backward Transfer 概论





# 最近的方向

- General CL
- FSCIL

异常检测（OOD）+持续学习



# 参考

Continual Learning（比萨大学）
