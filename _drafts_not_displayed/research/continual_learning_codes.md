---
title: 持续学习代码复现
date: 2022-08-14
categories: [有趣的事情]
tags: [技术]
img_path: /assets/img/
---

本文给一个我写的持续学习的代码框架，并复现一些基本的持续学习模型。我将突出写持续学习代码时可能遇到的问题，突出思想性的东西。水平很菜，仅供参考。前置知识请参考[《学习笔记：持续学习》]() 与[《动手学深度学习》读书笔记]()。


后向迁移与灾难性遗忘是一回事吗


前向迁移比后向迁移还要厉害嘛？


知识蒸馏技术与CL的关系


主动遗忘与模型容量分配问题？

# 持续学习框架（微调模型）

先搭建一个最简单的持续学习模型——微调模型，见《学习笔记：持续学习》。

## 构造持续学习场景

持续学习的数据集都是其他标准数据集现构造出来的，需要代码把数据集划分成不同的任务。以 MNIST 为例，要构造 Permuted MNIST 和 Split MNIST 两种数据集，分别对应 TIL、CIL 场景。

```python



```



dataloader 会在batch 和数据中间加一维以分隔；

多久采样一次 loss？一个epoch 一采？还是隔几个 batch？如何计算 loss？每次都算一次太占用。不科学。累加比较合适。

测试阶段，对每个任务 用 sub classifier 还是 fine-tuning classifier？

CIL 如何画三角图？


# iCaRL 方法



# 正则项


# 结构


