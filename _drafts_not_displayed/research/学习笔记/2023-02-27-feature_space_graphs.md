---
title: 深度学习论文中的特征空间图
date: 2023-02-27
categories: [科研]
tags: [机器学习]
img_path: /assets/img/
math: true
---

在特征空间上画图示意是一件很直观的事情。看了很多文章，觉得大家画的都很妙，就一眼觉得，嗯，很有道理那种。这篇笔记比较临时吧，就是把一些有意思的画图拿出来称赞一番。

深度神经网络和老式的浅层学习一样，可以看成两部分：特征提取器和输出头。输入 $$\mathbf{x}\in \mathbf{R}^{D}$$ 经过特征提取器得到特征 $$\mathbf{h}\in \mathbf{R}^{H}$$，再过最后一层输出头完成任务，如分类等。网络学习时大部分的工作是调整特征提取器的参数，使得各个 $$\mathbf{x}$$ 通过后得到的 $$\mathbf{h}$$ 能分布的比较“好”（“好”体现在各种方面，例如同一类别的样本凑在一起，不同任务的样本分的很开等等），为了使简单的输出头部分更容易的学习。因此，把**特征 $$\mathbf{h}$$ 分布的空间画出来，示意其学习前后发生的变化**，就是对模型、算法的直观解释。

特征空间的变化形式上以上面点的位置变化来体现，所以有时图中会以箭头等形式指出点位置的移动，并不是真的在移动点，而是特征空间更新的体现。在图中，通常会以不同标识符（颜色、形状等）区分数据点的类别、任务、领域等信息。对数据点也可以加不同的箭头说明模型、算法的不同模块起到的作用。

以下是一个典型的例子，来自论文：[Gradient Regularized Contrastive Learning for Continual Domain Adaptation]()

![](feature_space_graphs_example-1.png)

此论文解决了持续领域自适应问题。图中


以后有机会我再搜罗一下其他的图，放在这里。