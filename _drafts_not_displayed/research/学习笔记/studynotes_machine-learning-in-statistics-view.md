---
title: 统计视角下的机器学习
date: 2021-04-20
categories: [科研]
tags: [课程笔记]
img_path: /assets/img/
math: true
---

在一般人眼里，对深度学习、机器学习是按照**模型视角**来理解的：机器学习就是建立一个有输入有输出的模型，然后利用数据依照训练算法更新模型。但我们经常会在书籍、论文里见到很多用**统计视角**来描述机器学习的，里面通篇的概率统计式子，什么条件概率啊、期望啊、似然啊。

我是数学专业学生，但不是统计出身，在深度学习中，看到这些东西就头大，然后跳过。一直以来，我都觉得概率公式只是统计专业习惯写法，按模型视角理解完全够用，对我来说不过显得高级点而已。但我最近决定好好地学习一下统计视角，想总结一下如何在统计视角下看机器学习。希望以后在机器学习内容中看到概率统计式子时彻底不发怵。原因如下：
- 统计视角是一个更高的角度，让你对机器学习所做的事情有更深的理解；
- 随着我接触了更多的机器学习领域（尤其是无监督学习），发现有很多任务的理论体系都是用概率描述的，所以必须学习统计视角（对于这些任务，我也会在本文中详解）。

本文推荐参考书：李航《统计学习方法》，此书是能站在统计视角就站，非常地统计。读完我的这篇笔记，我认为应该会对书中提到的各种机器学习模型的定位和关系有更清楚的认识。



# 概论

无论在模型视角还是统计视角，机器学习都是表示、学习、推断三步，只是建立的模型和过程不一样。

|   | 表示 | 学习 | 推断 | 
| :-:| :-:| :-:| :-:| 
| 模型视角 | 对决策函数建模 | 优化算法，最小化损失函数 | 直接计算结果 | 
| 统计视角 | 对概率分布建模（概率模型） | 对分布进行估计（一般是参数估计）| 计算各种结果的概率值 |

如上所述，统计视角作为一个更高的角度，大部分机器学习事实上都可以看作概率模型。概率模型根据建模的对象，分为判别模型和生成模型。在详细展开各种判别和生成模型之前，我先举一个例子让大家感受一下两种视角的对比，是我们最耳熟能详的神经网络监督学习模型，它是判别模型。

## 例：神经网络监督学习模型的两种视角

设训练数据 $$\{(\mathbf{x}_i,y_i)\}_{i=1}^N$$，回归问题的模型视角：
- 表示：直接对该问题的输入输出建模为决策函数 $$y=f_\theta(\mathbf{x})$$，$$f$$可以是一个神经网络，参数为 $$\theta$$；
- 学习：选取参数 $$\theta$$ 使 $$f$$ 尽量拟合训练数据，即最小化损失函数 $$L(\theta) = \frac1N \sum_{i=1}^N l(f(\mathbf{x}_i), y_i)$$，通常选用平方损失 $$l(\hat{y}, y) = \frac12 |\hat{y}-y|^2$$；
- 推断：得到最优的决策函数后，给测试输入 $$\mathbf{x}$$，直接过决策函数 $$f$$ 计算输出 $$\hat{y}$$。

统计视角（翻开任何一本回归分析教材，这都是基础知识）：
- 表示：$$\mathbf{x},y$$ 是两个随机变量（由于是回归问题，所以是连续型随机变量），建模 $$y$$ 在 $$\mathbf{x}$$ 给定时（即条件分布 $$p(y|\mathbf{x})$$）服从**正态分布** $$N(f_\theta(\mathbf{x}),\sigma^2)$$，参数为 $$\theta, \sigma^2$$；
- 学习：使用训练数据（统计学一般称呼样本）对该条件正态分布进行参数估计，参数估计方法有很多种（见数理统计知识），常用**极大似然估计**（MLE）；
- 推断：得到最可能的条件分布后，给测试输入 $$\mathbf{x}$$，计算条件分布 $$p(y|\mathbf{x})$$ 的具体形式后，依据此分布预测 $$\hat{y}$$。最合理的方式是取最可能的值（因为参数估计是用极大似然估计得到的，测试阶段应与训练阶段吻合）：对此分布 $$N(f_\theta(\mathbf{x}),\sigma^2)$$ 来说概率密度最大点就是均值 $$f_\theta(\mathbf{x})$$（注：上面参数估计只估计 $$\theta$$ 其实就可以）。

**两种视角是等价的**，因为可以证明最大化正态分布的对数似然函数与最小化平方损失这两个优化问题是等价的。只需把两个目标函数化一化就出来了，无论回归分析还是机器学习的书籍都非常喜欢把这个当作习题，随便搜搜就能找到答案。

分类问题是类似的。$$C$$ 分类问题的模型视角：
- 表示：模型 $$\mathbf{o} = f_\theta(\mathbf{x})$$ 有 $$C$$ 个（中间）输出：$$\mathbf{o}=(o_0, o_1, \cdots, o_{C-1})$$，分别代表判断为各类的得分（实数）
- 学习：选取参数 $$\theta$$ 使训练数据通过模型的输出（过一次 Softmax） $$\hat{\mathbf{y}}=Softmax(\mathbf{o})$$ 尽量与其类别对应的 one-hot 向量接近，这里选用的损失函数都是交叉熵损失 $$l(\hat{\mathbf{y}}, \mathbf{y}) = -\sum_{c=0}^{C-1} y_c \log(\hat{y}_c)$$；
- 推断：得到最优的模型后，给测试输入 $$\mathbf{x}$$，取通过模型的输出（$$\mathbf{o}, \mathbf{y}$$ 皆可）最大者作为输出的类。
统计视角：
- 表示：$$y$$此时是一个离散型随机变量，可取的值只有 $$0,\cdots, C-1$$，只需对条件分布 $$P(y\|\mathbf{x})$$ 离散型分布列表格中的概率值建模： 
  | $$y$$ | 0 | 1 | ... | $$C-1$$ | 
  |:-:|:-:|:-:|:-:|:-:|
  | $$P(y\|\mathbf{x})$$ |  |  |  ... | |
  这些值要求是概率（0到1的数，和为1），是实数值 $$f_\theta(\mathbf{x})=(f_{\theta,0}(\mathbf{x}),\cdots, f_{\theta,C-1}(\mathbf{x}))$$ 通过一次 Softmax 得到的，最终归结为对 $$f_\theta(\mathbf{x})$$ 的建模。
  （如果非要看成是个概率分布，那这个离散分布应该是**重复次数为 1 的多项分布** $$MN(1, Softmax(f_\theta(\mathbf{x})))$$，参数为 $$\theta$$；
- 学习：仍是极大似然估计；
- 推断：仍然根据计算测试输入 $$\mathbf{x}$$ 的 $$P(y|\mathbf{x})$$（是 C 个概率值），取最大者作为输出的类。

也可以证明两种视角是等价的，即最大化多项分布的对数似然函数与最小化交叉熵损失等价。

可以看到，无论是那种视角，都绕不开对 $$f_\theta$$ 建模，模型视角直接建模，而统计视角须在逻辑上拐几个弯。$$f_\theta$$ 是神经网络，不同的建模将该模型叫成了多种名字：
- 线性回归：$$f_\theta$$ 是线性函数 $$\mathbf{w}^T \mathbf{x} + b$$，用于回归任务；
- 逻辑回归 / 多项逻辑回归（Softmax 回归）：$$f_\theta$$ 是线性函数，用于分类任务；
- 对数线性模型（最大熵模型）：$$f_\theta$$ 是输出层前有一层线性层的神经网络，用于分类任务；
- 深度学习：$$f_\theta$$ 是深度神经网络，用于分类、回归都可以。

> 上面对对数线性模型的表述不太严谨。对数线性模型的原意是：不对上述分类问题的 $$f_\theta(\mathbf{x})=(f_{\theta,0}(\mathbf{x}),\cdots, f_{\theta,C-1}(\mathbf{x}))$$ 直接建模，而是表示成更高维输出的线性组合：
$$f_\theta(\mathbf{x}) = \mathbf{W}^T g_\theta(\mathbf{x})$$
其中 $$g_\theta(\mathbf{x})=(g_{\theta,0}(\mathbf{x}),\cdots, g_{\theta,p-1}(\mathbf{x}))$$，$$p>C$$。如果这个 $$g_\theta$$ 被建模成神经网络的话，那么上面的表述是准确的。但在历史上，很多时候 $$g$$ 是直接使用别的手段提取的特征。 
{: .prompt-warning }

# 判别模型

上面的例子是一个判别模型。

在统计视角下，对**因变量对自变量的条件分布 $$p(y|\mathbf{x})$$**建模的模型称为**判别模型**（discriminative model）。对条件分布 $$p(y|\mathbf{x})$$ 不同的建模，得到不同的判别模型。从形式上可以看出，**它只适用于监督学习任务**（因为有因变量 $$y$$）。

对条件分布建模，看似是一个很唬人的东西，但首先，条件分布其实就是一系列普通的概率分布，$$\mathbf{x}$$ 虽然维度较高，但它写在条件里，只是一个下标性质的东西，用于索引关于 $$y$$ 的分布，而在监督学习中，$$y$$ 往往是一维的。第二，通过上面的例子可以看到，我们往往也不需要设计概率分布的形式，而是选用一个常用的分布（如正态分布），工作的重心于是归结为**设计分布参数**，注意它不是固定的数值，而是关于 $$x$$ 的函数，整个判别模型需要估计的参数就是这个函数的参数，例如上例的 $$f_\theta$$。

因此，很多判别模型本质上就是在设计模型视角下的决策函数，用统计视角来解释看起来像文字游戏，这也是机器学习初学者最常有的感觉和忽视统计视角的理由，因为他们可能认为上述神经网络监督学习就是机器学习模型的全部。但事实上，有一些判别模型是对条件分布 $$p(y|\mathbf{x})$$ 直接建模的。来看看下面的例子。

## 基于能量的模型（EBM）

上面我们看到，分类问题的条件分布是离散的，可以直接对离散的条件概率建模。由于对概率值（有大于 0 和为 1 的限制）建模不容易，所以都是将其看作实数值过 Softmax，再对实数值建模。而回归问题对应的条件分布是连续的，通常是选用正态分布。

但实际上，也可以采取类似的方式直接对连续的条件密度函数建模：密度函数就是普通的函数加了两条约束（大于 0 且积分为 1），可以由普通函数过归一化变换得到：
$$p(y|\mathbf{x})=\frac1{Z_\theta(\mathbf{x})}\exp(f_\theta(\mathbf{x},y))$$
因此，对概率函数的建模可以归结到对普通函数的建模，这个普通函数通常称为**能量函数**（有物理学解释）。之后的学习和推断不再赘述。

这种模型是直接在统计视角建立的，在模型视角下看不是直观的，需要一定的推导，感兴趣的话可以试试。


# 没有统计视角的机器学习模型

上述涉及的模型大都可以在两个视角下解释：神经网络监督学习很自然地有两个视角，基于能量的模型虽然模型视角不直观，但也是可以推导出来的。还是那句话，统计视角站的角度更高，一个机器学习模型，如果在统计视角建立，那么一定有模型视角（只是推导会比较复杂）；但在模型视角建立的，有的就无法给出合理的统计视角解释了。

在继续探索生成模型之前，我单独拿出一章总结**没有统计视角的机器学习模型**，它们就是纯粹的输入输出模型，在提出时就可能与统计没有半点关系。这些模型通常比后面的生成模型简单，而且是李航书中前期的大部头，因此放在前面来讲。它们包括：
- 感知机（Perceptron）；
- k 近邻（kNN）算法；
- 决策树；
- 支持向量机（SVM）；
- AdaBoost；
- ...

它们的原理与本文无关，我不会作介绍，请自行翻阅李航书。

但是我必须要提醒的是，很多这种模型容易与有统计视角的模型混淆。例如，感知机、支持向量机（只能解决二分类问题）的决策函数都是 $$f_\theta(\mathbf{x})=Sigmoid(\mathbf{w}^T\mathbf{x}+b)$$，与二项逻辑回归一模一样，但它们是不同的模型。导致不同的原因不是表示和推断过程，而是学习算法：
- 感知机的学习算法是基于误分类点的调整算法，等价于损失函数 $$l(f_\theta(\mathbf{x}), y) = [- y f_\theta(\mathbf{x})]_+$$；
- 支持向量机的学习算法依据间隔最大化原则，等价于合页损失函数 $$l(f_\theta(\mathbf{x}),y)=[1 - y f_\theta(\mathbf{x})]_+$$；
- 二项逻辑回归的学习算法使用交叉熵损失函数 $$l(\hat{\mathbf{y}}, \mathbf{y}) = -\sum_{c=0}^{C-1} y_c \log(\hat{y}_c)$$。

前两者没有统计视角解释，因为损失函数找不到合适的统计上的参数估计方法对应。而且逻辑回归使用的交叉熵损失可以与极大似然估计对应。


# 生成模型

在统计视角下，对**变量的联合分布**直接建模的模型称为**生成模型**（generative model），这里的变量可以是自变量（即$$p(\mathbf{x})$$），也可以是自变量和因变量（$$p(\mathbf{x},y)$$）。它可以用于监督学习，也更广泛地用于无监督学习。

对于监督学习，需要建模条件分布 $$p(y|\mathbf{x})$$，生成模型先对自变量的分布 $$p(\mathbf{x})$$ 和与因变量的联合分布 $$p(\mathbf{x},y)$$ 建模，然后根据条件概率公式：
$$p(y|\mathbf{x}) = \frac{p(\mathbf{x},y)}{p(\mathbf{x})}$$
间接地得到条件分布的模型。要提醒的几点：
- 它和判别模型的一大区别是，$$\mathbf{x}$$ 的角色不再是索引条件分布中的下标，而是真正的随机变量，需要对其分布建模了，而它是高维的，相比于判别模型本质上只需要建模 1 维的分布，挑战性大得多了；
- 对 $$p(\mathbf{x})$$ 和 $$p(\mathbf{x},y)$$ 作假设，是比直接对 $$p(y|\mathbf{x})$$ 作假设，包含的信息更多的，表示更复杂，也要承担更大的学习代价；
- 推断过程不是直接的，至少需要多一步代上述公式得到 $$p(y|\mathbf{x})$$ 的步骤。因此在书中经常大篇幅讲解生成模型的推断过程；
- 生成模型也是直接在统计视角建立的，在模型视角下看不是直观的，因此书中介绍他们都是直接用统计的语言。这也是只懂模型视角容易捉襟见肘的一个体现。
 
对于无监督学习，没有因变量 $$y$$，生成模型就是对自变量的分布 $$p(\mathbf{x})$$ 建模。

先来说有了 $$p(\mathbf{x})$$ 能做什么，即无监督学习的推断过程。无监督学习的任务种类繁多，不像监督学习只是单纯地给输入求预测：
- **密度估计**：$$p(\mathbf{x})$$ 就是想要的结果，任务已经完成了；
- **生成**：生成和训练数据类似的样本。从分布 $$p(\mathbf{x})$$ 采样是比较简单的生成方式，但大部分情况是由隐变量间接生成，见“隐变量机制”一节；
- **推断**（inference）：给测试样本的部分变量 $$\mathbf{e}$$（$$\mathbf{x}$$ 的子集），预测剩余某个或某些变量 $$\mathbf{q}$$。通常借助 Bayes 公式计算 $$\mathbf{q}$$ 对已知变量的条件分布 $$p(\mathbf{q}|\mathbf{e})$$，根据此来预测：
$$p(\mathbf{q}|\mathbf{e}) = \frac{p(\mathbf{q},\mathbf{e})}{p(\mathbf{e})} = \frac{\sum_\mathbf{z} p(\mathbf{x})}{\sum_{\mathbf{q},\mathbf{z}} p(\mathbf{x})}$$
（注：连续情形改为积分号）问题转化为如何对如何求一个分布 $$p(\mathbf{x})$$ 的边缘分布。

> 此推断非表示、学习、推断中的推断，为避免混淆，以后称其为 inference 任务。
{: .prompt-warning }

下面讨论如何对 $$p(\mathbf{x})$$ 建模。正在学数理统计的同学会发现这很熟悉——可以直接假设 $$p(\mathbf{x})$$ 服从某一分布（离散情况如泊松分布，连续情况如正态分布等），用样本数据对其参数进行估计。不用怀疑，这样做是完全没问题的，就是无监督生成模型最单纯的思路。但是这个模型太简单了，难以应付无监督学习中高维的、复杂的数据。试想，比如数据是一堆图片，谁会简单地假设图像的像素点符合一个多维正态分布呢。也就是说，**对高维数据直接作某个分布的假设是太简单了、太强了**。

为此，统计学家设计出了各种模型，并不只是设计了一个更复杂的分布，而是会引入一些表示方法的新机制，如隐变量机制，由此衍生出一堆关于该机制的理论，等等。因此，这一部分内容比关注于设计网络结构的判别模型更繁琐艰深，每种模型都有独特的逻辑、机制和思想值得去学习。

下面将介绍各种表示方法，包括图关系表示、隐变量机制等，一并这些表示方法通用的学习和推断算法。本章最后列举使用到这些表示方法的例子，都是很经典的，有一些有自己特有的学习和推断算法，也会作一些讨论。



## 图关系表示

当 $$\mathbf{x}=(x_1,\cdots,x_m)$$ 维度太高时，直接建模不太容易下手。一个思路是对随机变量 $$x_1,\cdots,x_m$$ 之间具有某种关系，在这些关系的基础上建模。笼统地说，将变量之间的关系建模为图关系的模型统称为**概率图模型**（Graphical Model）。图关系有有向图、无向图两种，从而有**有向图模型**、**无向图模型**两类概率图模型。

### 有向图模型

**有向图模型**将 $$p(\mathbf{x})$$ 按照概率的乘法公式
$$p(\mathbf{x}) = p(\mathbf{x}_r |\mathbf{x}_c) p(\mathbf{x}_c)$$
不断分解成各种条件分布与边缘分布的乘积，再对这些低维的分布建模就很容易了。同时，如果结点代表变量，条件概率代表有向边，$$p(\mathbf{x})$$ 就可以用一个有向图表示出来。下面将从头推导 $$p(\mathbf{x})$$ 的分解，并解释它与有向图的对应关系。

首先，在使用乘法公式分解 $$p(\mathbf{x})$$ 时，我们约定一次只取一个变量放在条件左边，即（注意 $$x_r$$ 小写）
$$p(\mathbf{x}) = p(x_r |\mathbf{x}_c) p(\mathbf{x}_c)$$
只分解一步往往是不行的，因为 $$p(\mathbf{x}_c)$$ 只比 $$p(\mathbf{x})$$ 低一维，仍然很高维，需要继续递归地分解下去，共 $$m$$ 次，直到变成一堆**一维条件分布与一维边缘分布的积**，对一维分布建模是简单的：

$$p(\mathbf{x}) = p(x_{i_1}|x_{i_2},\cdots,x_{i_m})  p(x_{i_2}|x_{i_3},\cdots,x_{i_m})\cdots  p(x_{i_{m-1}}|x_{i_m})  p(x_{i_m})$$
其中 $$(i_1,\cdots,i_m)$$ 是 $$(1,\cdots,m)$$ 的一个顺序。

若以变量为结点，为条件概率中每个条件后的变量（可能有多个）连一条有向边到条件前的变量（只有一个），则它与全体**完全有向无环图**是一一对应的。完全有向无环图是能连则连的，所以由拓扑序（上述$$(i_1,\cdots,i_m)$$）完全决定，可以看到，这种分解方式也完全由每次“取到左边”变量的顺序决定。

大多数时候，上述分解仍然是个复杂的模型，所以会对变量之间作一些**条件独立性假设**：

$$p(x_r|\mathbf{x}_c) = p(x_r|\mathbf{x}_{c'}), c'\subset c$$。

这样简化了条件分布的尾巴，也减少了图的一些边，从而与全体**有向无环图**一一对应。这种模型就叫**有向图模型**，又称**贝叶斯网络**、**信念网络**。$$p(\mathbf{x})$$ 最终的分解的形式为：

$$p(\mathbf{x})=\prod_{j=1}^m p(x_j|\mathbf{x}_{\pi_j})$$

注意该式已经把一维的边缘分布囊括进来了，因为 $$\pi_j$$ 可以是空集。



以下总结有向图模型表示、学习、推断的过程：

- 表示：分成两步：
  - 为实际问题中的变量 $$x_1,\cdots,x_m$$ 设计一个有向无环图。由于其中每条有向边 $$e_{i\rightarrow j}$$ 代表 $$p(\mathbf{x})$$ 出现一个 $$p(x_j|x_i)$$ 的条件概率，所以它反映的是变量间的**因果关系**，在设计图时应该遵循此关系，将“因”变量连到“果”变量；
  - 对分解的一维分布建模，如正态分布，次数为 1 的多项分布等；
- 学习：使用训练数据对 $$p(\mathbf{x})$$ 的分解形式作极大似然估计；
- 推断：有向图模型应用最大的无监督任务是 inference 任务，上面已经说了归结为求一些变量的边缘分布问题，解决此问题的算法有：
  - **精确推断算法**：变量消除法、信念传播算法等（在维度太高时计算代价很大）；
  - **近似推断算法**：MCMC、Gibbs 采样等。

> 在实际问题表示成有向图模型时，加的条件独立性假设不是随意的，必须满足一定性质使能以上面的方式构成有向无环图，这个性质称为**马尔可夫性**：存在一个变量排序 $$x_{i_1},\cdots,x_{i_m}$$，使得所有条件独立性假设 $$p(x_{i_r}|\mathbf{x}_c) = p(x_{i_r}|\mathbf{x}_{c'}),c'\subset c$$ 中的 $$\mathbf{x}_c$$ 必须为 $$(x_{i_1},\cdots,x_{i_{r-1}})$$。
> 可以证明该排序若存在则唯一，并且就是上述拓扑序。
{: .prompt-info }

例：

![](Bayesian_network_example.png)


### 无向图模型

**无向图模型**，又称**马尔可夫随机场**（MRF)，是另一种 $$p(\mathbf{x})$$ 分解方式，它难以像有向图模型那样直观地推导分解过程并与图结构对应，这里就直接给出结果。

无向图模型也是对变量之间作了一些概率分布上的假设，也是一些**条件独立性假设**，形式同上：

$$p(x_r|\mathbf{x}_c) = p(x_r|\mathbf{x}_{c'}), c'\subset c$$。

使得 $$p(\mathbf{x})$$ 能分解成一系列非负函数的乘积（这些函数称为**能量函数**）：

$$p(\mathbf{x})=\frac1Z \prod_{c\in\mathcal{C}} \phi_c(\mathbf{x}_c),\ Z = \sum_{\mathbf{x}}  or  \int_\mathbf{x} \prod_{c\in\mathcal{C}} \phi_c(\mathbf{x}_c)$$  

其中 $$\mathcal{C}$$ 是 $$(1,\cdots,m)$$ 的子集 $$c$$ 的集合。

若以变量为结点，将条件独立性假设中 $$x_r$$ 与 $$\mathbf{x}_{c'}$$ 对应的结点以无向边相连，则它与全体**无向图**是一一对应的，对应方式为：$$\mathcal{C}$$ 是无向图所有**最大团**构成的集合。注意，无向图的最大团集合和无向图完全决定无向图，所以是一一对应。

以下总结无向图模型表示、学习、推断的过程：

- 表示：分成两步：
  - 就是为实际问题中的变量 $$x_1,\cdots,x_m$$ 设计一个无向图。无向边反映的是变量间普通的**依赖关系**，在设计图时应该遵循此关系，将有依赖关系的变量以无向边相连；有了无向图后，求它所有的最大团 $$c$$（有很多算法，如 Bron-Kerbosch 算法），得到 $$p(\mathbf{x})$$ 的分解式；
  - 对分解出来的各个能量函数 $$\phi_c(\mathbf{x})$$ 建模（注意它只要保证非负即可，它不是概率分布）；
- 学习：同上；
- 推断：同上。

> 在实际问题表示成无向图模型是时，加的条件独立性假设也不是随意的，必须满足一定性质使能以上面的方式构成无向图。这个性质称为**局部马尔可夫性**：所有条件独立性假设 $$p(x_r|\mathbf{x}_c) = p(x_r|\mathbf{x}_{c'}),c'\subset c$$ 中的 $$\mathbf{x}_c$$ 必须是除 $$x_r$$ 的所有其他变量。
{: .prompt-info }

## 隐变量机制

以上我们研究的只涉及已知信息的随机变量 $$\mathbf{x}=(x_1,\cdots,x_m)$$。为了将模型变复杂，假设还有一些别的随机变量 $$\mathbf{z}=(z_1,\cdots,z_s)$$ 参与到分布中起作用，此时的研究对象从 $$p(\mathbf{x})$$ 变为了 $$p(\mathbf{x},\mathbf{z})$$（$$\mathbf{z}$$ 与 $$\mathbf{x}$$ 的关系就蕴含其中）。

我们手头只有 $$\mathbf{x}$$ 而没有 $$\mathbf{z}$$ 的样本，所以 $$\mathbf{z}$$ 被称为**隐变量**。带了隐变量的概率模型称为**隐变量模型**（Latent Variable Model）。

以下总结隐变量模型表示、学习、推断的过程：
- 表示：根据对实际问题的认识，考虑一下有哪些值得关注的但是无法观测的变量，将其引入为隐变量 $$\mathbf{z}$$，对分布 $$p(\mathbf{x},\mathbf{z})$$ 建模。建模时一般会利用实际问题中隐变量与显变量的联系，所以要将其分解为 $$p(\mathbf{x}|\mathbf{z})p(\mathbf{z})$$，对二者分别建模；
- 学习：从逻辑上看，没有 $$\mathbf{z}$$ 的样本是无法完整地估计 $$p(\mathbf{x},\mathbf{z})$$ 的，那该怎么办呢？应当转变思维：不一定非要精确的 $$p(\mathbf{x},\mathbf{z})$$，估计个大概也行啊（反正要用的也不是完整的 $$p(\mathbf{x},\mathbf{z})$$，而是它的边缘分布 $$p(\mathbf{x})$$）。这个近似算法就是著名的**期望最大化（EM）算法**。我不打算讲解原理（任何统计教材中都有），只要记住它是**带隐变量的概率模型的学习算法**——由显变量的 $$\mathbf{x}$$ 的样本估计借助隐变量估计其分布 $$p(\mathbf{x}, \mathbf{z})$$ 的算法。
- 推断：隐变量模型应用于很多无监督任务：
  - inference 任务：
    - 由显变量推断显变量：直接求 $$p(\mathbf{x}, \mathbf{z})$$ 的边缘分布 $$p(\mathbf{x})$$，用此分布作推断；
    - 由显变量推断隐变量：求出 $$p(\mathbf{z}|\mathbf{x})$$，用此分布做推断；
  - 生成任务：根据分解 $$p(\mathbf{x},\mathbf{z})=p(\mathbf{x}|\mathbf{z})p(\mathbf{z})$$，先根据 $$p(\mathbf{z})$$ 对 $$\mathbf{z}$$ 采样，再根据 $$p(\mathbf{x}|\mathbf{z}))$$ 对 $$\mathbf{x}$$ 采样（类似于由隐变量推断显变量）。（注：它**等价于**直接从分布 $$P(\mathbf{x}) = \sum_{z} P(\mathbf{x},\mathbf{z}) or \int_z p(\mathbf{x},\mathbf{z})$$ 中采样。）

> 带隐变量机制的生成模型可以用于监督学习中，其中因变量 $$y$$ 和 $$\mathbf{x}$$ 一样是显变量。
{: .prompt-tip }




## 例子

以上是两种模型表示的机制，可以组合出很多实用的模型。有的是有特定的图结构，有的是对分布进行特定的建模。下面作介绍。

### Sigmoid 信念网络

Sigmoid 信念网络（SBN）是有向图模型，应用于自变量 $$\mathbf{x}$$ 都取值 0 或 1 的情况，此时一维的条件分布和边缘分布都只能是多项分布（准确来说是 0-1 分布 $$B(1,p)$$）。一般的有向图模型会尝试把分布列中所有能作为参数的概率值都作为参数，类似于上面的例子。

SBN 将条件分布中的分布参数 $$p$$ 建模为与条件后变量的线性组合有关（为了让其落在 $$[0,1]$$ 区间成为合法参数，过了一次 Sigmoid）：
$$x_j | x_{\pi_j} \sim B(1, p),\  p = Sigmoid(\mathbf{w}^T x_{\pi_j})$$
这样，设 $$x_{\pi_j}$$ 维数为 $$m_j$$，如果把分布列的位置全部作为模型参数，则有 $$2^{m_j}$$ 个参数，而 SBN 使其减少到 $$m_j + 1$$ 个，大大减少了参数量。

SBN 的图结构可以是任意的，可以带隐变量也可以不带，可用于无监督学习也可用于监督学习。它的关注点在如何对分解出来的概率分布建模。

SBN 的学习算法使用醒眠算法（Wake-Sleep Algorithm），适用于带隐变量的 SBN，原理类似于 EM 算法。


## 朴素贝叶斯分类器

**朴素贝叶斯分类器**（Naïve Bayes Classifier）是有向图模型，只用于监督学习：**自变量是有限取值的分类问题**（在监督学习中，这种对自变量的要求导致它几乎无法用到常见的实际场合）。它采用的图结构：
- 因变量 $$y$$ 作为“因”，自变量 $$\mathbf{x}$$ 作为果，即 $$y$$ 指向所有 $$x_1, \cdots, x_m$$ 的有向边；
- 自变量之间都有条件独立性假设，即除了上述有向边不存在任何其他边。
据此，$$P(\mathbf{x},y)$$ 分解为：
$$P(\mathbf{x},y) = P(x_1|y)\cdots P(x_m|y)P(y)$$

> 应该注意的是，$$y$$ 建模为 “因” 而不是 “果”。如果建模为 “果”，就成了直接给因变量对自变量的条件分布 $$p(y|\mathbf{x})$$建模了，就不是生成模型了。
{: .prompt-warning }

朴素贝叶斯分类器可以直接用极大似然估计学习，除此之外还有贝叶斯估计，见李航书。

### 对数线性模型

这里说的对数线性模型和前面判别模型中的对数线性模型是完全不同的，这里是一种生成模型：能量函数能表示成如下形式的无向图模型称为**对数线性模型**：

$$\phi_c(\mathbf{x}_c)=\exp{(\theta_c^T f_c(\mathbf{x}_c))}$$  

每个能量函数是（对应最大团里）变量的某些**固定**特征的线性组合（过一个指数函数使其成为合法的能量函数）。参数就是这些特征的权重，而不考虑特征函数内部的情况。

对数线性模型的图结构可以是任意的，它的关注点在如何对分解出来的能量函数建模。

### 隐马尔可夫模型

带隐变量，有向图


### 条件随机场

带隐变量

### 玻尔兹曼机


### 受限玻尔兹曼机


## 深度信念网络



### 深度学习的可解释性：统计角度

什么是可解释性？从模型角度，。。。


从统计角度，就是知道任意中间变量 z (真正意义的中间变量)。统计是个更高的角度，由条件分布可以导出一个判别函数，最简单的取概率最大只。反过来不行。统计是一个更高的角度！

普通的监督学习的深度网络其实就是经过很多层中间变量的图模型。


学习完了，中间任取一层中间变量（真正意义上的中间变量）当作隐变量，我们只知道判别函数 $$z=f(x)$$,$$p(x|z)$$，具体是啥，$$p(z|x)$$ 具体是啥。或者相邻两层之间 $$p(z_1|z_2)$$ 具体是啥。


## 非图模型的例子


### 混合模型

**混合模型**是一个带隐变量的非图模型，用于无监督学习。在建模 $$p(\mathbf{x})$$ 时，它引入了一个隐变量 $$z$$。正如上文所说，隐变量模型通常不直接对 $$p(\mathbf{x},z)$$建模，而是利用 $$p(\mathbf{x}|z)p(z)$$，对二者分别建模。混合模型将二者建模如下：

- $$P(z)$$：$$z$$ 是离散型随机变量，有有限个取值 $$1,\cdots,K$$，分布列中各概率值为 $$\pi_k$$；
- $$p(\mathbf{x}|z)$$：$$p(\mathbf{x}|z)=\mathbf{1}[z=k]p_k(\mathbf{x})$$，

其中 $$p_k$$ 是固定的带参数的分布，例如正态分布 $$N(\mu_k, \sigma_k^2)$$，对应的称为**高斯混合模型**（GMM）等。

混合模型的分布参数是 $$z$$ 分布列的各概率值和 $$p_k$$ 的参数，以 GMM 为例，分布参数是 $$\pi_k, \mu_k, \sigma_k^2$$。学习算法为 EM 算法。

混合模型的隐变量只是起到了构造辅助作用，因此一般它不会被用于推断，此时直接求出 $$\mathbf{x}$$ 的边缘分布即可：

$$p(\mathbf{x}) = \sum_{k=1}^K P(\mathbf{x},z)= \sum_{z=1}^K P(\mathbf{x}|z)P(z) = \sum_{z=1}^K \pi_k p_k(\mathbf{x})$$

> 不要把它简单地理解成一种特殊的分布，即每个子分布的权重 $$\pi_k$$ 是定值（超参数）。混合模型的精髓就在于权重 $$\pi_k$$ 是作为分布参数学习得到的，而不是人为规定的。（但由于 $$z$$ 是没有样本，所以必须使用 EM 算法而不是普通的极大似然估计）
{: .prompt-danger }


### 深度生成模型

以下介绍近年来比较火的**深度生成模型**。深度生成模型就是指使用深度神经网络对分布建模（在学习时相应地用到神经网络的反向传播算法）的生成模型。

在判别模型那边可以看到，神经网络一般用于建模条件分布，这里也是一样的。以下模型的内核使用隐变量机制，引入隐变量 $$\mathbf{z}$$，研究对象分解为 $$p(\mathbf{x},\mathbf{z})=p(\mathbf{x}|\mathbf{z})p(\mathbf{z})$$使用神经网络建模的是 $$p(\mathbf{x}|\mathbf{z})$$ 建模。但是，不同的模型对 $$p(\mathbf{z})$$ 的处理方式不同。

最简单的处理方式是直接假设 $$p(\mathbf{z})$$ 为某个常用的分布，通过 EM 算法学习。但是，在 $$\mathbf{z}$$ 没有实际意义且没有其他信息的情况下，做出这样的假设是很强的，某种程度上和直接对 $$p(\mathbf{x})$$ 作某个分布的假设没什么区别。

在深度学习中，我们希望自动地找到合适的 $$p(\mathbf{z})$$，而不是人为地作假设。自编码器（Autoencoder）试图做到这一点。注意自编码器不是一个生成模型，它的任务是学到更低维的表示（表示学习），而不是完成生成等任务。从统计视角来看，其做法是借助 $$p(\mathbf{x}|\mathbf{x})=p(\mathbf{x}|\mathbf{z})p(\mathbf{z}|\mathbf{x})$$，通过对 $$p(\mathbf{x}|\mathbf{x})$$ 作极大似然估计（在模型视角是最小化重建损失），学习成对的 $$p(\mathbf{x}|\mathbf{z})$$、$$p(\mathbf{z}|\mathbf{x})$$。

我们先从最简单的想法开始，它并不实用，但方便引入实用的 VAE、GAN 等模型的思想。

#### 简单的

这个模型

> 隐变量个数不能比 $$\mathbf{x}$$ 多，否则神经网络会学习到 $$\mathbf{z}$$ 的子集到 $$\mathbf{x}$$ 的恒等映射，失去了建模的意义。
{: .prompt-warning }


表示学习+生成任务
下面都是，使用表示学习。表示学习是一种隐变量的。在图模型中，可以看做 x 到 z 全连接的形状，箭头考虑两边（而不是普通的隐变量jizhi ），

### 朴素的隐变量监督模型（toy example）





引入 z 当作 z->x  的监督任务

它是个 toy，也是个模型，就单独开一节了。


自己学的后果：
- Generator 自己学（当作传统的监督学习）。相当于向量到图片，像图像分类反过来。
- 问题是输入的向量如何产生。随机产生肯定不好，容易相似的离得很远；所以需要人来设计。

下面的VAE和GAN 算是从这个方面的改进。





### 自编码器（Autoencoder）与 变分自编码器（VAE）



自编码器不适合划分到生成模型或者判别模型的任一类，有点四不像。因为它没有对 p(x) 或者 p(x,z) 建模。讲他主要是为了引出 VAE。

站在模型视角出发看更加合适，先说模型视角。我们学了一个重建函数，然后最小化重建损失函数。模型假设是它经过了哪些中间变量，如何经过的。例如对神经网络，中间有几层，每层几个神经元。

在统计视角下，设 x 是随机变量，它其实是对 $$p(x|x)$$ 建模。没错，它必须服从在 x 处概率为 1 的分布列（连续情况是 dirac 函数）。这甚至连假设都算不上，只是概率论的定理。

可以证明，对它作极大似然估计（样本只需x）对应了重建损失。


模型有很多中间变量（必须是真正意义上的中间，即它决定于 x，且重建x 完全决定于它，例如前向网络的一层），任取一层 $$\mathbf{z}$$，则重建函数 x' = R(x) 可拆成拆成两个函数 Encoder，Decoder
 z = Encoder(x)  x'=Decoder(z)
 
 通过上面的优化过程学习完毕，得到了两个具体的函数 Encoder，Decoder，这两个函数是互逆的，从而 z 可以作为x 的一个**表示**。换句话说，把输入空间作了一个变换，变换空间与原空间一一对应。能可逆是很重要的。
 （平时看到的网络的某一层只能叫 嵌入 Embedding，因为不可逆，把输入空间嵌入。这种东西甚至不用学，直接构造Embedding 函数即可）。学习可逆的表示是一个无监督任务，称为表示学习，Autoencoder 就是做这个的。

 > z 维数必须比 x 低很多。否则会偷懒，copy 恒等映射！！中间任何一层都要这样。而且也没有意义，为什么要学一个更高维的东西表示它呢？找麻烦。


 从统计角度看，中间变量可以看成为隐变量 $$\mathbf{z}$$，自编码器是一个隐变量模型。
 
从分布的角度，在考虑 $$p(x|x) = p(x|z)p(z|x)$$。
统计是一个更高的角度，可以认为 $$p(z|x)$$, $$p(x|z)$$ 根据某种策略（例如最大概率）生成了决策函数 Encoder，Decoder，但是学习完后我们手里有的不知道它们的具体是什么样子的！就像回归那样，知道了决策函数，就是知道了真太分布 $$N(f(x),)$$。换句话说，学到的那个表示是不可解释的。


要想让它可解释，应该对 $$p(x|z),p(z|x)$$ 作假设，核心矛盾在于， $$p(x|z)$$ 和 $$p(z|x)$$ 是联动的、耦合的，因为它们都是 $$p(x,z)$$ 的产物（受到的约束是 p(x|z)p(z|x)=p(x|x)）。我们在做假设的时候，不能独立地 $$p(x|z)$$ 和 $$p(z|x)$$，会与概率公式矛盾。而我们不能显示地表示它们的联动关系。

自编码器的做法则是不对二者任意之一作显示的分布假设，让二者根据概率论公理的限制 + 通过决策函数的启发，自动地来学。

Autoencoder 拿来作生成任务是很勉强的，不是说效果不好，而是逻辑不通，为了逻辑通顺只能做一些不合理的近似。我说的当然不是根据 $$p(x)$$，因为Autoencoder 压根没有估计出来 p(x)过它，而是估计 $$p(x|x)$$。当然也不能根据 $$p(x|x)$$  来生成（自己不能生成自己啊hhh），而是通过隐变量 z 就是隐变量机制那里讲的
p(x,z) = p(x|z) p(z)

Autoencoder 算是估计出了 p(x|z)，体现在 Decoder 函数上，但是 p(z) 是不知道的！解决方案：
- Autoencoder 还估计出来了 p(z|x)，可以近似替代一下 p(z)，但它是通过 Encoder 函数，x 从哪儿来？只有样本可以用。如果拿 x 来生成 z，最后生成的结果 x' 只能和 x 极度相似。
- 那我完全可以 z 随便取，过一下Decoder，但这样没道理（相当于胡乱假设了 p(z)）效果肯定不如生成出来的z好。

变分自编码器 2014提出，。



上面第一条的解决方案，试图用 $$p(z|x)$$ 近似替代 $$p(z)$$。它们两个的唯一不同，就是 $$p(z|x)$$ 是很多个分布（视x不同取值而不同），如果不管 x 取什么值，都 $$p(z|x)$$ 都一样，此时说明 $$x$$ 与 z 独立，于是 $$p(z|x)$$ 就等于 $$p(z)$$ 了。

VAE 的想法就是在学习的过程中，不仅限制其学到可逆的变换（即重建损失函数 或虽大似然估计），还限制 $$p(z|x)$$ 必须都靠近某个固定的分布：即最小化 p(z|x) 与此固定分布的 KL三度（是衡量分布接近程度的工具）。损失函数是二者的综合。要优化这种损失函数可不容易，幸亏 VAE 的作者通过再参数化（Reparameterization）的技巧将其转化成了梯度下降法可以用的形式，使他引入的损失函数VAE项可以统一跟着似然用梯度下降法，不再详述。

另外要说明，VAE 作者建议固定的分布选择标准正态分布，在论文里有解释。通过引入此机制，VAE 可以像。。隐变量那样完成生成任务：从标准正态分布中生成 z，在过 Decoder 生成 x。由于$$p(z|x)$$ 就等于 $$p(z)$$，用到了$$p(x,z) = p(x|z)p(z)$$，因此，变分自编码器应当划归到生成模型。

从一个固定的分布产生 z，然后学习 z ，这个模型上与上面那个 naive 的模型是一样的。区别在于怎么训练，上面的需要 z 的样本，而这个不需要，而是充分挖掘了 x 自身的信息。


### 生成对抗网络（GAN）

另一种不需要 z 样本的。

GAN 也是基于 $$p(x,z) = p(x|z)p(z)$$，

Generator 后加了 Discriminator，Discriminator 是启发式的。

思想 两种：对抗关系、教师学生

从训练算法的角度（而不是逻辑的）合看成一个网络
算法 必须固定下层的 discriminator，否则只需调后面几层参数，让output全都是 1


经验：AutoEncoder 需要更大的网络才能得到和 GAN 相同的效果。直观原因？没有考虑样本间的关系？


### 单独使用 Discrimator 的模型

用一个 Discriminator 。argmax最大值。类似CNN可视化某一层。。不穷举。
Discriminator 更倾向于，，像老师、文学批评家。
最主要的问题是只有正样本，没有负样本，它会倾向于把所有东西盘城正的。。非常考验负样本的收集技术。它是手动的。



好的负样本某种程度上是生成出来的。这里的一个算法是可以一开始随机副样本，相当于 GAN 的geneator 不单独搞了，直接用 discriminate的argmax。穷举是不可能的，。通常又一些开率论的假设。这就是graphic model（见lhy ppt），概率图模型，沈心意讲的那节。STructure learning 传统技术。


会不会这个generator 和discri 是相同的知识，导致反复否定自己，反复横跳？？lhy ppt？？？

讲  Generator dis 各自的优缺点，然后配合起来才能互补。（lhy 第一节课最后）


不如把他们分独立开，这也是GAN的一个想法来源。




# Bayes 观点




总结上面所谓的统计视角，都是对概率分布进行建模，学习算法即对分布参数的估计，这其实属于统计学中**概率学派**的视角。统计学中还有一种视角来源于 **Bayes（贝叶斯）学派**，Bayes 学派和概率学派的主要区别就是把不把**分布的参数当作随机变量**。这两个学派在历史上经常吵来吵去，但基本是互相对应的，真真确确地是一个事情的两种解释，其实完全可以不用了解。经典的参考书籍是 [PRML]()，作者 Christopher Bishop 是一个坚定的贝叶斯人，通篇都以 Bayes 学派的视角解释机器学习，以下大部分内容也是参考此书。



> 要注意，上面出现的带 Bayes 名字的东西都与 Bayes 观点无关。Bayes 公式只是概率论中的基本公式，朴素 Bayes 是指用了 Bayes 公式推导，Bayesian 网络也只是一个名词。
{: .prompt-tip }



可以解释正则化



学习算法就是=参数估计。。，模型=概率模型。。训练数据 = 样本

记号上，分布参数一般写在p下标，也有写分号后，这些都是常规写法，。但也有人写在条件里的，比较逆天，尤其是贝叶斯



隐变量与参数其实看起来没什么不同，如果放在bayes观点来看？主要是 EM 算法对它的处理让它与众不同。


## Bayes 观点下的监督学习

不管是判别模型还是生成模型，都要建模 $$p(y|x)$$。由于这里把 \theta 看作随机变量，应写为 $$p(y|x,\theta)$$。一个特点是把数据集 $$D = (X,Y)$$ 也引入到随机变量中（而不是看作x,y的样本），所以是 $$p(y|x,\theta,D)$$。


给了数据集 D，先验分布 $$p(\theta)$$（通常都是假设连续的），求后验分布 $$p(\theta|D)$$。训练过程在贝叶斯术语中称为推断（inference），就是根据贝叶斯公式：

一个细节很重要：先验分布 $$p(\theta)$$ 和 $$p(\theta|X)$$ 是一样的。\theta 与 x 无关，只有给了y 才有关。

$$ p(\theta|D) =p(\theta|X,Y) =  \frac{p(Y|X,\theta) p(\theta|X)}{\int p(Y|X,\theta) p(\theta|X)d\theta} = \frac{p(Y|X,\theta) p(\theta)}{\int p(Y|X,\theta) p(\theta)d\theta} $$ 求出后验分布。（注意不要把整个D翻过来，而是只翻 Y）数据集 D 的信息蕴含在似然函数 $$p(Y|X,\theta)$$ 里:i.i.d.

$$p(Y|X,\theta) = \prod_{i=1}^N p(y_i| x_i,\theta) $$

分母即归一化即可。

测试阶段即预测（prediction）。有了后验分布：

方法一：简单地从后延分布 $$p(\theta|D)$$ 中找最可能的 $$\theta$$ 值 $$\theta^\star$$，然后使用模型 $$p(y|x,\theta^\star)$$ 来预测。这叫最大后验概率估计（MAP），不是纯正的贝叶斯。

方法二：这是纯正的 Bayes 方法

而是平均：

$$p(y|x,D) = \int p(y,\theta|x,D) d\theta = \int p(y|\theta,x,D) p(\theta |x,D) d\theta = \int p(y|x,\theta,D) p(\theta |D) d\theta$$


对于复杂的，是不是方法一二时间上相同？


> 概率分布不如神经网络表示能力强。所以现在神经网络更火。