---
title: 使用训练信息的持续学习
date: 2022-11-15
categories: [科研]
tags: [论文笔记, 机器学习, 持续学习]
img_path: /assets/img/
math: true
---

有一类持续学习方法的想法是从旧任务的训练过程中获取信息，存放在记忆中，作为新任务防遗忘的参考。本文统一介绍这种思路。这类方法是为了防止遗忘，属于防遗忘机制的另一种分类法。

此类方法的两要素：

- 有哪些训练信息可以利用？
- 获得的训练信息如何使用？

下面依次讨论，并给出几篇论文使用的例子。

# 训练信息

我所谓的训练信息是指随训练过程得到的中间产物，而不是原始的训练数据等信息。这类思路的好处是不会带来额外的计算量，因为所用信息是从训练过程中就地取材的，训练过程是无论如何都要进行的。

可以利用的训练信息通常有每步更新时的：
- 梯度；
- 前向传播得到的损失；
- 参数值，更新前后参数的变化（可以通过梯度的大小反映）；
- 其他指标的变化量；
- 特征；
- 网络的 Lipschitz 性（用 Lipschitz 常数来刻画）
- 训练的 mask 重合程度。

有的会在训练过程中人为引入一些额外的过程（会带来一些额外的计算量）。一个常见的是向前看（look-ahead）的方法：向前看一步的更新，计算完相关的信息后，退回不实际实施这一步更新。

这些信息一般不会全部加以利用，需要整合或筛选。整合的简单方法是简单地将各步平均，筛选可以简单地随机抽取，也可以设计一定的规则。

# 使用方法

获得的训练信息如何使用到新任务的训练中是第二个要点。以下是几种方式。

- 直接限制更新方向，训练信息通常是梯度；
- 在损失函数中构造正则项，例如用特征构造蒸馏损失；
- 构造其他的信息，使用此信息间接地作用新任务训练，如任务相似度。


# 论文例子

## OGD

正交梯度下降（OGD）是基于梯度的方法，见[持续学习基础知识笔记]()。

使用的训练信息是旧任务的梯度，用于限制新任务的更新方向——投影到垂直于旧任务梯度张成的空间。


## Task Grouping

Task Grouping 方法原论文为[]()，是多任务场景，可以改造成迭代的持续学习场景。

训练信息是使用旧任务的损失，引入了额外的过程，即向新任务更新方向（损失降低方向）向前看一步，以在各旧任务上损失降低的大小作为任务相似度信息，据此划分给新任务不同的任务分组影响新任务的训练。

## 我的方法

Mask 的重合程度也可以看成一个训练信息。