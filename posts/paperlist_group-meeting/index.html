<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="zh-cn"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="组会论文/报告列表（长期更新）" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="这是我组组会上讨论的论文与报告列表，按照时间倒序排序。每篇论文给出以下信息： 论文链接：点击论文题目即可； 出版信息：会议、期刊、预印本等； 作者：一般不详细列举，因为复制一遍这些信息实在没什么意义，只大体写一下主要作者所在的机构。仅对感兴趣的、值得关注的作详细的标注； 组会主讲人：均为本组博士生，以字母代替； 内容简介（空着的是懒得写了…）。" /><meta property="og:description" content="这是我组组会上讨论的论文与报告列表，按照时间倒序排序。每篇论文给出以下信息： 论文链接：点击论文题目即可； 出版信息：会议、期刊、预印本等； 作者：一般不详细列举，因为复制一遍这些信息实在没什么意义，只大体写一下主要作者所在的机构。仅对感兴趣的、值得关注的作详细的标注； 组会主讲人：均为本组博士生，以字母代替； 内容简介（空着的是懒得写了…）。" /><link rel="canonical" href="https://pengxiang-wang.github.io/posts/paperlist_group-meeting/" /><meta property="og:url" content="https://pengxiang-wang.github.io/posts/paperlist_group-meeting/" /><meta property="og:site_name" content="Shawn Wang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-09-19T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="组会论文/报告列表（长期更新）" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-27T23:26:31+08:00","datePublished":"2022-09-19T00:00:00+08:00","description":"这是我组组会上讨论的论文与报告列表，按照时间倒序排序。每篇论文给出以下信息： 论文链接：点击论文题目即可； 出版信息：会议、期刊、预印本等； 作者：一般不详细列举，因为复制一遍这些信息实在没什么意义，只大体写一下主要作者所在的机构。仅对感兴趣的、值得关注的作详细的标注； 组会主讲人：均为本组博士生，以字母代替； 内容简介（空着的是懒得写了…）。","headline":"组会论文/报告列表（长期更新）","mainEntityOfPage":{"@type":"WebPage","@id":"https://pengxiang-wang.github.io/posts/paperlist_group-meeting/"},"url":"https://pengxiang-wang.github.io/posts/paperlist_group-meeting/"}</script><title>组会论文/报告列表（长期更新） | Shawn Wang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Shawn Wang"><meta name="application-name" content="Shawn Wang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/avatar.jpg " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Shawn Wang</a></div><div class="site-subtitle font-italic">WPX 的个人主页</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>时间表</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于本站</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pengxiang-wang" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://space.bilibili.com/88684674" aria-label="bilibili" target="_blank" rel="noopener"> <i class="fas fa-tv"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shawn.pxwang','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>组会论文/报告列表（长期更新）</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>组会论文/报告列表（长期更新）</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://github.com/pengxiang-wang">Shawn Wang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1663516800" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-09-19 </em> </span> <span> 更新于 <em class="timeago" data-ts="1685201191" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-05-27 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="4456 字"> <em>24 分钟</em>阅读</span></div></div></div><div class="post-content"><p>这是我组组会上讨论的论文与报告列表，按照时间倒序排序。每篇论文给出以下信息：</p><ul><li>论文链接：点击论文题目即可；<li>出版信息：会议、期刊、预印本等；<li>作者：一般不详细列举，因为复制一遍这些信息实在没什么意义，只大体写一下主要作者所在的机构。仅对感兴趣的、值得关注的作详细的标注；<li>组会主讲人：均为本组博士生，以字母代替；<li>内容简介（空着的是懒得写了…）。</ul><p>我的其他关于论文的博文中出现论文元信息时，也遵从上述原则。对于需要详细讲解的论文，一般不会写内容简介。</p><h1 id="2022-2023-第二学期">2022-2023 第二学期</h1><h2 id="2023-05-25"><span class="mr-2">2023-05-25</span><a href="#2023-05-25" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="dualprompt-complementary-prompting-for-rehearsal-free-continual-learning"><span class="mr-2"><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860617.pdf"><span class="mr-2">DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning</a></span><a href="#dualprompt-complementary-prompting-for-rehearsal-free-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ECCV 2022<li>作者：东北大学，谷歌<li>主讲人：H<li>内容：</ul><h3 id="prompt-tuning-few-shot-learning"><span class="mr-2">Prompt-Tuning Few-shot learning</span><a href="#prompt-tuning-few-shot-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>主讲人：L<li>内容：讲解几篇使用 Prompt-Tuning 的小样本学习工作的思想。</ul><h2 id="2023-03-02"><span class="mr-2">2023-03-02</span><a href="#2023-03-02" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="gradient-regularized-contrastive-learning-for-continual-domain-adaptation"><span class="mr-2"><a href=""><span class="mr-2">Gradient Regularized Contrastive Learning for Continual Domain Adaptation</a></span><a href="#gradient-regularized-contrastive-learning-for-continual-domain-adaptation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：AAAI 2021<li>作者：悉尼大学，香港中文大学，商汤<li>主讲人：W<li>内容：</ul><h3 id="learnable-istribution-calibration-for-few-shot-class-incremental-learning"><span class="mr-2"><a href="https://arxiv.org/abs/2210.00232"><span class="mr-2">Learnable istribution Calibration for Few-Shot Class-Incremental Learning</a></span><a href="#learnable-istribution-calibration-for-few-shot-class-incremental-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>发表：ArXiv 2022<li>作者：中国科学院大学，华为等<li>主讲人：Z<li>内容：小样本持续学习</ul><h2 id="2022-02-23"><span class="mr-2">2022-02-23</span><a href="#2022-02-23" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="task-customized-self-supervised-pre-training-with-scalable-dynamic-routing"><span class="mr-2"><a href="https://ojs.aaai.org/index.php/AAAI/article/view/20079"><span class="mr-2">Task-Customized Self-Supervised Pre-training with Scalable Dynamic Routing</a></span><a href="#task-customized-self-supervised-pre-training-with-scalable-dynamic-routing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：AAAI 2022<li>作者：华为诺亚方舟实验室<li>主讲人：L<li>内容：</ul><h3 id="new-insights-for-the-stability-plasticity-dilemma-in-online-continual-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=fxC7kJYwA_a"><span class="mr-2">New Insights for the Stability-Plasticity Dilemma in Online Continual Learning</a></span><a href="#new-insights-for-the-stability-plasticity-dilemma-in-online-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2023<li>作者：首尔国立大学<li>主讲人：H<li>内容：<ul><li>组合了不同的 Normalization 方法，BN 负责稳定性部分，LN、IN（广泛地应用于迁移学习）负责可塑性部分。<li>为重演样本提出了限制散开程度的损失。</ul></ul><h2 id="2022-02-16"><span class="mr-2">2022-02-16</span><a href="#2022-02-16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>（假期进展汇报）</p><h1 id="2022-2023-第一学期">2022-2023 第一学期</h1><h2 id="2022-11-14"><span class="mr-2">2022-11-14</span><a href="#2022-11-14" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="一个小样本任务微调的框架"><span class="mr-2">一个小样本任务微调的框架</span><a href="#一个小样本任务微调的框架" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>主讲人：L<li>内容：</ul><h3 id="s3c-self-supervised-stochastic-classifiers-for-few-shot-class-incremental-learning"><span class="mr-2"><a href="https://link.springer.com/chapter/10.1007/978-3-031-19806-9_25"><span class="mr-2">S3C: Self-Supervised Stochastic Classifiers for Few-Shot Class-Incremental Learning</a></span><a href="#s3c-self-supervised-stochastic-classifiers-for-few-shot-class-incremental-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ECCV 2022<li>作者：印度科学理工学院（班加罗尔）<li>主讲人：Z<li>内容：</ul><h3 id="快慢网络式持续学习与任务相似性机制的结合"><span class="mr-2">快慢网络式持续学习与任务相似性机制的结合</span><a href="#快慢网络式持续学习与任务相似性机制的结合" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>主讲人：W</ul><h2 id="2022-11-07"><span class="mr-2">2022-11-07</span><a href="#2022-11-07" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="cross-domain-cross-set-few-shot-learning-via-learning-compact-and-aligned-representations"><span class="mr-2"><a href="https://openreview.net/forum?id=MpJjrfSJ-Xs"><span class="mr-2">Cross-Domain Cross-Set Few-Shot Learning via Learning Compact and Aligned Representations</a></span><a href="#cross-domain-cross-set-few-shot-learning-via-learning-compact-and-aligned-representations" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022<li>主讲人：L<li>内容：</ul><h3 id="temporal-latent-bottleneck-synthesis-of-fast-and-slow-processing-mechanisms-in-sequence-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=mq-8p5pUnEX"><span class="mr-2">Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning</a></span><a href="#temporal-latent-bottleneck-synthesis-of-fast-and-slow-processing-mechanisms-in-sequence-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2022<li>作者：蒙特利尔大学、微软、DeepMind、CIFAR 等<li>主讲人：Z<li>内容：</ul><h3 id="on-the-effectiveness-of-lipschitz-driven-rehearsal-in-continual-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=TThSwRTt4IB"><span class="mr-2">On the Effectiveness of Lipschitz-Driven Rehearsal in Continual Learning</a></span><a href="#on-the-effectiveness-of-lipschitz-driven-rehearsal-in-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>发表：NIPS 2022<li>作者：意大利两所不出名大学<li>主讲人：H</ul><h2 id="2022-10-31"><span class="mr-2">2022-10-31</span><a href="#2022-10-31" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="worst-case-matters-for-few-shot-recognition"><span class="mr-2"><a href="https://link.springer.com/chapter/10.1007/978-3-031-20044-1_6"><span class="mr-2">Worst Case Matters for Few-Shot Recognition</a></span><a href="#worst-case-matters-for-few-shot-recognition" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ECCV 2022<li>作者：南京大学，计算机软件新技术国家重点实验室<li>主讲人：L<li>内容：</ul><h3 id="do-deep-networks-transfer-invariance-across-classes"><span class="mr-2"><a href="https://openreview.net/forum?id=Fn7i_r5rR0q"><span class="mr-2">Do Deep Networks Transfer Invariance Across Classes?</a></span><a href="#do-deep-networks-transfer-invariance-across-classes" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022<li>作者：斯坦福大学、宾夕法尼亚大学，Finn 组<li>主讲人：Z<li>内容：</ul><h3 id="compacting-picking-and-growing-for-unforgetting-continual-learning"><span class="mr-2"><a href="https://proceedings.neurips.cc/paper/2019/hash/3b220b436e5f3d917a1e649a0dc0281c-Abstract.html"><span class="mr-2">Compacting, Picking and Growing for Unforgetting Continual Learning</a></span><a href="#compacting-picking-and-growing-for-unforgetting-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2019<li>作者：（台湾）中央研究院资讯科学研究所<li>主讲人：W<li>内容：参数隔离方法，是先训练后剪枝重新训练的 PackNet 的改进：在训练新任务时，选出旧任务参数的一部分在剪枝时也重新训练。选择哪些参数是学习了在旧任务参数上的 mask，旧任务参数是固定的，类似 Piggyback 训 mask 的方式。</ul><h2 id="2022-10-24"><span class="mr-2">2022-10-24</span><a href="#2022-10-24" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="curvature-adaptive-meta-learning-for-fast-adaptation-to-manifold-data"><span class="mr-2"><a href="https://ieeexplore.ieee.org/abstract/document/9749838/"><span class="mr-2">Curvature-Adaptive Meta-Learning for Fast Adaptation to Manifold Data</a></span><a href="#curvature-adaptive-meta-learning-for-fast-adaptation-to-manifold-data" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议/期刊：ICCV 2021, TPAMI 2022<li>作者：北京理工大学计算机学院，贾云得组<li>主讲人：L<li>内容：</ul><h3 id="efficiently-identifying-task-groupings-for-multi-task-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=hqDb8d65Vfh"><span class="mr-2">Efficiently Identifying Task Groupings for Multi-Task Learning</a></span><a href="#efficiently-identifying-task-groupings-for-multi-task-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：Google、斯坦福大学，Finn 组<li>主讲人：W<li>内容：多任务学习场景的任务分组方法，基于任务相似度为任务作分组，划分模型分组训练小的多任务。任务相似度计算自训练过程的损失变化。其中任务分组、任务相似性的度量可以借鉴到持续学习上。</ul><h3 id="exemplar-free-class-incremental-learning-via-discriminative-and-comparable-one-class-classifiers"><span class="mr-2"><a href="https://arxiv.org/abs/2201.01488"><span class="mr-2">Exemplar-free Class Incremental Learning via Discriminative and Comparable One-class Classifiers</a></span><a href="#exemplar-free-class-incremental-learning-via-discriminative-and-comparable-one-class-classifiers" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>发表：ArXiv 2022<li>作者：北京交通大学<li>主讲人：Z<li>内容：</ul><h2 id="2022-10-17"><span class="mr-2">2022-10-17</span><a href="#2022-10-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="持续学习中区分高频低频信息的想法"><span class="mr-2">持续学习中区分高频/低频信息的想法</span><a href="#持续学习中区分高频低频信息的想法" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>主讲人：H<li>内容：关于持续学习中区分高频/低频信息的想法</ul><h3 id="margin-based-few-shot-class-incremental-learning-with-class-level-overfitting-mitigation"><span class="mr-2"><a href="https://openreview.net/forum?id=hyc27bDixNR"><span class="mr-2">Margin-Based Few-Shot Class-Incremental Learning with Class-Level Overfitting Mitigation</a></span><a href="#margin-based-few-shot-class-incremental-learning-with-class-level-overfitting-mitigation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2022<li>作者：华中科技大学，北京大学<li>主讲人：Z<li>内容：通过实验发现了持续学习在每个任务上不能学得太狠，最好学个大概即可。</ul><h3 id="主题"><span class="mr-2">(主题)</span><a href="#主题" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>论文：<ul><li><a href="https://openreview.net/forum?id=JWOiYxMG92s">Free Lunch for Few-shot Learning: Distribution Calibration</a><li><a href="https://openreview.net/forum?id=qOgSCLE5E8">Adaptive Distribution Calibration for Few-Shot Learning with Hierarchical Optimal Transport</a><li><a href="https://www.aaai.org/AAAI22Papers/AAAI-2032.TaoR.pdf">Powering Finetuning for Few-shot Learning: Domain-Agnostic Bias Reduction with Selected Sampling</a></ul><li>会议/期刊：<ul><li>ICLR 2021 Oral, TPAMI 2022<li>NIPS 2022<li>AAAI 2022</ul><li>作者：<ul><li>悉尼科技大学<li>香港中文大学，深圳市人工智能与机器人研究院<li>CMU</ul><li>主讲人：L<li>内容：</ul><h3 id="基于-mask-的持续学习"><span class="mr-2">基于 mask 的持续学习</span><a href="#基于-mask-的持续学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>论文：<ul><li><a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Mallya_PackNet_Adding_Multiple_CVPR_2018_paper.pdf">PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning</a><li><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Arun_Mallya_Piggyback_Adapting_a_ECCV_2018_paper.pdf">Piggyback: Adapting a Single Network to Multiple Tasks by Learning to Mask Weights </a><li><a href="https://openreview.net/forum?id=r1gdj2EKPB">Scalable and Order-robust Continual Learning with Additive Parameter Decomposition</a><li><a href="https://proceedings.neurips.cc/paper/2020/hash/ad1f8bb9b51f023cdc80cf94bb615aa9-Abstract.html">Supermasks in Superposition</a></ul><li>会议：<ul><li>CVPR 2018<li>ECCV 2018<li>ICLR 2020<li>NIPS 2020</ul><li>作者：<ul><li>伊利诺伊大学香槟分校<li>伊利诺伊大学香槟分校<li>韩国 KAIST，AITRICS<li>华盛顿大学等</ul><li>主讲人：W<li>内容：整理了持续学习加 Mask 的论文，为这一类方法总结出了一个分类体系（见<a href="">持续学习笔记</a> 的网络结构法部分）。</ul><h2 id="2022-10-10"><span class="mr-2">2022-10-10</span><a href="#2022-10-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="cross-attention-multi-scale-vision-transformer-for-image-classification"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_CrossViT_Cross-Attention_Multi-Scale_Vision_Transformer_for_Image_Classification_ICCV_2021_paper.pdf"><span class="mr-2">Cross-Attention Multi-Scale Vision Transformer for Image Classification</a></span><a href="#cross-attention-multi-scale-vision-transformer-for-image-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICCV 2021<li>作者：MIT-IBM Watson AI Lab<li>主讲人：Z<li>内容：Cross-ViT</ul><h3 id="training-data-efficient-image-transformers--distillation-through-attention"><span class="mr-2"><a href="https://proceedings.mlr.press/v139/touvron21a.html"><span class="mr-2">Training data-efficient image transformers &amp; distillation through attention</a></span><a href="#training-data-efficient-image-transformers--distillation-through-attention" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICML 2021<li>作者：Facebook<li>主讲人：Z<li>内容：DeiT</ul><h3 id="meta-baseline-exploring-simple-meta-learning-for-few-shot-learning"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Meta-Baseline_Exploring_Simple_Meta-Learning_for_Few-Shot_Learning_ICCV_2021_paper.pdf"><span class="mr-2">Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning</a></span><a href="#meta-baseline-exploring-simple-meta-learning-for-few-shot-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICCV 2021<li>作者：UC San Diego，UC Berkeley 等<li>主讲人：L<li>内容：</ul><h3 id="overcoming-catastrophic-forgetting-with-hard-attention-to-the-task"><span class="mr-2"><a href="https://proceedings.mlr.press/v80/serra18a.html"><span class="mr-2">Overcoming Catastrophic Forgetting with Hard Attention to the Task</a></span><a href="#overcoming-catastrophic-forgetting-with-hard-attention-to-the-task" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICML 2018<li>作者：西班牙巴塞罗那的大学<li>主讲人：W<li>内容：持续学习模型 HAT，是将 mask 机制加到持续学习的第一篇论文，提出了一个很简单的、每个神经元引入一个任务 mask 的方法，并给出了训练方法，和一个解决模型容量问题的稀疏正则项，让新旧任务 mask 重合。它属于参数隔离方法，之后很多带 mask 机制的持续学习论文以此篇为基础。</ul><h3 id="梯度操控法持续学习"><span class="mr-2">梯度操控法持续学习</span><a href="#梯度操控法持续学习" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>论文：<ul><li><a href="https://proceedings.mlr.press/v108/farajtabar20a.html">Orthogonal Gradient Descent for Continual Learning</a><li><a href="https://www.nature.com/articles/s42256-019-0080-x">Continual Learning of Context-dependent Processing in Neural Networks</a><li><a href="https://openreview.net/forum?id=3AOj0RCNC2">Gradient Projection Memory for Continual Learning</a></ul><li>会议/期刊：<ul><li>AISTATS 2020<li>Nature Machine Intelligence 2019<li>ICLR 2021</ul><li>作者：<ul><li>DeepMind<li>中科院自动化所，类脑智能研究中心<li>普渡大学</ul><li>主讲人：W<li>内容：三篇基于梯度修正的持续学习论文，是这种方法最早、最经典的工作。第一、三篇把新任务的梯度投影到垂直于旧任务子空间的方向，为了防止覆盖旧任务的知识。二者的区别在第一篇直接拿旧任务用过的梯度张成子空间，第三篇是用旧任务数据（奇异值分解出的向量）构造。第二篇工作直接归结为一个修正梯度的矩阵，对其使用 RLS 算法迭代更新。</ul><h2 id="2022-09-19"><span class="mr-2">2022-09-19</span><a href="#2022-09-19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="meta-attention-for-vit-backed-continual-learning"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Xue_Meta-Attention_for_ViT-Backed_Continual_Learning_CVPR_2022_paper.pdf"><span class="mr-2">Meta-attention for ViT-backed Continual Learning</a></span><a href="#meta-attention-for-vit-backed-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CVPR 2022<li>作者：浙江大学、阿里<li>主讲人：Z<li>内容：</ul><h3 id="dytox-transformers-for-continual-learning-with-dynamic-token-expansion"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Douillard_DyTox_Transformers_for_Continual_Learning_With_DYnamic_TOken_eXpansion_CVPR_2022_paper.pdf"><span class="mr-2">DyTox: Transformers for Continual Learning with DYnamic TOken eXpansion</a></span><a href="#dytox-transformers-for-continual-learning-with-dynamic-token-expansion" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CVPR 2022<li>作者：法国索邦大学<li>主讲人：Z<li>内容：</ul><h3 id="a-multi-head-model-for-continual-learning-via-out-of-distribution-replay"><span class="mr-2"><a href="https://virtual.lifelong-ml.cc/poster_33.html"><span class="mr-2">A Multi-head Model for Continual Learning via Out-of-distribution Replay</a></span><a href="#a-multi-head-model-for-continual-learning-via-out-of-distribution-replay" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CoLLAs 2022<li>作者：伊利诺伊大学芝加哥分校，Bing Liu 组<li>主讲人：Z<li>内容：</ul><h3 id="channel-importance-matters-in-few-shot-image-classification"><span class="mr-2"><a href="https://proceedings.mlr.press/v162/luo22c/luo22c.pdf"><span class="mr-2">Channel Importance Matters in Few-Shot Image Classification</a></span><a href="#channel-importance-matters-in-few-shot-image-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICML 2022<li>作者：电子科技大学，哈尔滨工业大学<li>主讲人：L</ul><h3 id="variational-continual-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=BkQqq0gRb"><span class="mr-2">Variational Continual Learning</a></span><a href="#variational-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2018<li>作者：剑桥大学<li>主讲人：W<li>内容：从贝叶斯学派角度提出了一个持续学习框架——变分持续学习（VCL），提出框架是主要的。同时提出了一个在此框架下简单的防止遗忘的机制——coreset。</ul><h3 id="improving-and-understanding-variational-continual-learning"><span class="mr-2"><a href="https://arxiv.org/pdf/1905.02099.pdf"><span class="mr-2">Improving and Understanding Variational Continual Learning</a></span><a href="#improving-and-understanding-variational-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>发表：ArXiv 2019<li>作者：剑桥大学<li>主讲人：W<li>内容：对上一篇文章在训练技巧上做了一点改进，同时讨论了 VCL 特有的现象——剪枝效应。作者认为剪枝效应对持续学习意义是很大的</ul><h1 id="2021-2022-第二学期">2021-2022 第二学期</h1><h2 id="2022-04-27"><span class="mr-2">2022-04-27</span><a href="#2022-04-27" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="modeling-label-space-interactions-in-multi-label-classification-using-box-embeddings"><span class="mr-2"><a href="https://openreview.net/forum?id=tyTH9kOxcvh"><span class="mr-2">Modeling Label Space Interactions in Multi-label Classification using Box Embeddings</a></span><a href="#modeling-label-space-interactions-in-multi-label-classification-using-box-embeddings" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Poster)<li>作者：马萨诸塞大学阿默斯特分校<li>主讲人：L<li>内容：</ul><h3 id="model-behavior-preserving-for-class-incremental-learning"><span class="mr-2"><a href="https://ieeexplore.ieee.org/document/9705128"><span class="mr-2">Model Behavior Preserving for Class-Incremental Learning</a></span><a href="#model-behavior-preserving-for-class-incremental-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：IEEE TNNLS 2022<li>作者：西安交通大学<li>主讲人：H<li>内容：</ul><h2 id="2022-04-20"><span class="mr-2">2022-04-20</span><a href="#2022-04-20" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="数据增强论文整理"><span class="mr-2">数据增强论文整理</span><a href="#数据增强论文整理" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>主讲人：L</ul><h3 id="continual-learning-with-recursive-gradient-optimization"><span class="mr-2"><a href="https://openreview.net/forum?id=7YDLgf9_zgm"><span class="mr-2">Continual Learning with Recursive Gradient Optimization</a></span><a href="#continual-learning-with-recursive-gradient-optimization" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Spotlight)<li>作者：清华大学计算机系<li>主讲人：W<li>内容：本文可以看成是加正则项的持续学习方法。</ul><h3 id="leanring-a-unified-calssifier-incrementally-via-rebalancing"><span class="mr-2"><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.pdf"><span class="mr-2">Leanring a Unified Calssifier Incrementally via Rebalancing</a></span><a href="#leanring-a-unified-calssifier-incrementally-via-rebalancing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CVPR 2019<li>作者：中科大、香港中文大学等<li>主讲人：Z<li>内容：</ul><h2 id="2022-04-13"><span class="mr-2">2022-04-13</span><a href="#2022-04-13" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="maml-is-a-noisy-contrastive-learner-in-classification"><span class="mr-2"><a href="https://openreview.net/forum?id=LDAwu17QaJz"><span class="mr-2">MAML is a Noisy Contrastive Learner in Classification</a></span><a href="#maml-is-a-noisy-contrastive-learner-in-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Poster)<li>作者：（台湾）国立交通大学<li>主讲人：L<li>内容：</ul><h3 id="the-close-relationship-between-contrastive-learning-and-meta-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=gICys3ITSmj"><span class="mr-2">The Close Relationship Between Contrastive Learning and Meta-learning</a></span><a href="#the-close-relationship-between-contrastive-learning-and-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Poster)<li>作者：马里兰大学<li>主讲人：L<li>内容：</ul><h3 id="representational-continuity-for-unsupervised-continual-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=9Hrka5PA7LW"><span class="mr-2">Representational Continuity for Unsupervised Continual Learning</a></span><a href="#representational-continuity-for-unsupervised-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Oral)<li>作者：<ul><li>纽约大学、韩国科学院、清华大学智能产业研究院等</ul><li>主讲人：W<li>内容：这是一篇将持续学习用在无监督场景的论文，做的实验、内容还是比较综合的：里面既涉及到比较火的无监督学习模型，也把持续学习的三大类方法中比较新提出的推广到无监督场景中。目前看挺适合入门一下无监督的持续学习。无监督学习是一般是学习表示，让无监督学习持续起来，也就是题目所述的“Representational Continuity”。</ul><h2 id="2022-04-06"><span class="mr-2">2022-04-06</span><a href="#2022-04-06" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="confess-a-framework-for-single-source-cross-domain-few-shot-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=zRJu6mU2BaE"><span class="mr-2">ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning</a></span><a href="#confess-a-framework-for-single-source-cross-domain-few-shot-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022<li>作者：高通 AI 研究院<li>主讲人：L<li>内容：</ul><h2 id="2022-03-16"><span class="mr-2">2022-03-16</span><a href="#2022-03-16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="cope-continual-prototype-evolution-learning-online-from-non-stationary-data-streams"><span class="mr-2"><a href="https://openreview.net/forum?id=Tt1s9Oi1kCS"><span class="mr-2">(CoPE) Continual Prototype Evolution: Learning Online from Non-Stationary Data Streams</a></span><a href="#cope-continual-prototype-evolution-learning-online-from-non-stationary-data-streams" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2021<li>作者：比利时鲁汶大学<li>主讲人：W<li>内容：</ul><h1 id="2021-2022-第一学期">2021-2022 第一学期</h1><h2 id="2021-12-17"><span class="mr-2">2021-12-17</span><a href="#2021-12-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="context-aware-attentional-pooling-cap-for-fine-grained-visual-classification"><span class="mr-2"><a href=""><span class="mr-2">Context-aware Attentional Pooling (CAP) for Fine-grained Visual Classification</a></span><a href="#context-aware-attentional-pooling-cap-for-fine-grained-visual-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：AAAI 2021<li>作者：英国边山大学<li>主讲人：L<li>内容：</ul><h2 id="2021-12-10"><span class="mr-2">2021-12-10</span><a href="#2021-12-10" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="bns-building-network-structures-dynamically-for-continual-learning"><span class="mr-2"><a href="https://proceedings.neurips.cc/paper/2021/hash/ac64504cc249b070772848642cffe6ff-Abstract.html"><span class="mr-2">BNS: Building Network Structures Dynamically for Continual Learning</a></span><a href="#bns-building-network-structures-dynamically-for-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：北大数据科学中心、胡文鹏（北大数院信息系）、王选计算机研究所、Bing Liu<li>主讲人：Z<li>内容：将强化学习用于持续学习中，在每个task中训练一个agent用来决策网络结构和初始化，使其训练后能在验证集上达到最优效果，reward包含当前task和之前task，达到防止遗忘和知识迁移两个目的。训练代价大，每个task之间agent似乎没有联系，没有真正将持续学习和强化学习联系起来。</ul><h3 id="is-class-incremental-enough-for-continual-learning"><span class="mr-2"><a href="https://www.frontiersin.org/articles/10.3389/frai.2022.829842/full"><span class="mr-2">Is Class-Incremental Enough for Continual Learning?</a></span><a href="#is-class-incremental-enough-for-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：Frontiers in AI 2022<li>作者：Andrea Cossu*, Gabriele Graffieti, Lorenzo Pellegrini, Davide Maltoni, Davide Bacciu, Antonio Carta, Vincenzo Lomonaco<li>主讲人：W<li>内容：</ul><h3 id="does-continual-learning--catastrophic-forgetting"><span class="mr-2"><a href=""><span class="mr-2">Does Continual Learning = Catastrophic Forgetting?</a></span><a href="#does-continual-learning--catastrophic-forgetting" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>发表：ArXiv 2021<li>作者：Anh Thai, Stefan Stojanov, Zixuan Huang, Isaac Rehg, James M. Rehg<li>主讲人：W<li>内容：</ul><h2 id="2021-12-03"><span class="mr-2">2021-12-03</span><a href="#2021-12-03" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="memory-efficient-class-incremental-learning-for-image-classification"><span class="mr-2"><a href="https://ieeexplore.ieee.org/document/9422177"><span class="mr-2">Memory Efficient Class-Incremental Learning for Image Classification</a></span><a href="#memory-efficient-class-incremental-learning-for-image-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：IEEE TNNLS 2021<li>作者：浙江大学计算机学院<li>主讲人：W<li>内容：</ul><h2 id="2021-11-26"><span class="mr-2">2021-11-26</span><a href="#2021-11-26" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="iirc-incremental-implicitly-refined-classification"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Abdelsalam_IIRC_Incremental_Implicitly-Refined_Classification_CVPR_2021_paper.pdf"><span class="mr-2">IIRC: Incremental Implicitly-Refined Classification</a></span><a href="#iirc-incremental-implicitly-refined-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CVPR 2021<li>作者：蒙特利尔大学等<li>主讲人：Z<li>内容：提出了持续学习中出现不同粒度的类别，且相互关系未知。用多标签分类的指标作为评价标准，在几个经典算法上观察了实验效果，说明了粗细粒度的关系会影响分类效果。</ul><h3 id="hcv-hierarchy-consistency-verification-for-incremental-implicitly-refined-classification"><span class="mr-2"><a href="https://www.bmvc2021-virtualconference.com/assets/papers/0008.pdf"><span class="mr-2">HCV: Hierarchy-Consistency Verification for Incremental Implicitly-Refined Classification</a></span><a href="#hcv-hierarchy-consistency-verification-for-incremental-implicitly-refined-classification" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：BMVC 2021<li>作者：西班牙巴塞罗那的大学，南开大学<li>主讲人：Z<li>内容：针对IIRC问题提出了判断类别关系的方法，根据前面类别的打分确定是否为之前某一类的子类。超类和子类同时输出高分。测试时根据训练得到的层级关系调整矛盾的预测结果。</ul><h2 id="2021-11-19"><span class="mr-2">2021-11-19</span><a href="#2021-11-19" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="overcoming-catastrophic-forgetting-in-incremental-few-shot-learning-by-finding-flat-minima"><span class="mr-2"><a href="https://openreview.net/forum?id=ALvt7nXa2q"><span class="mr-2">Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima</a></span><a href="#overcoming-catastrophic-forgetting-in-incremental-few-shot-learning-by-finding-flat-minima" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：香港科技大学<li>主讲人：H<li>内容：</ul><h3 id="intriguing-properties-of-contrastive-losses"><span class="mr-2"><a href="https://openreview.net/forum?id=rYhBGWYm6AU"><span class="mr-2">Intriguing Properties of Contrastive Losses</a></span><a href="#intriguing-properties-of-contrastive-losses" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：Google<li>主讲人：L<li>内容：</ul><h2 id="2021-11-12"><span class="mr-2">2021-11-12</span><a href="#2021-11-12" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="efficiently-identifying-task-groupings-for-multi-task-learning-1"><span class="mr-2"><a href="https://openreview.net/forum?id=hqDb8d65Vfh"><span class="mr-2">Efficiently Identifying Task Groupings for Multi-Task Learning</a></span><a href="#efficiently-identifying-task-groupings-for-multi-task-learning-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：Google、斯坦福大学，Finn 组<li>主讲人：Z<li>内容：<ul><li>目的：设计高效的多任务分组方法。<li>方法：提出 inter-task affinity，用a任务的梯度方向观察b任务的损失函数变化情况，以此刻画任务间的相关程度。<li>主要结论：此算法和SOTA相比在测试准确率不降低的情况下大幅减少了计算时间。</ul></ul><h3 id="meta-learning-with-an-adaptive-task-scheduler"><span class="mr-2"><a href="https://openreview.net/forum?id=MTs2adH_Qq"><span class="mr-2">Meta-learning with an Adaptive Task Scheduler</a></span><a href="#meta-learning-with-an-adaptive-task-scheduler" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：斯坦福大学，中科大，腾讯 AI Lab 等，Finn 组<li>主讲人：H<li>内容：</ul><h2 id="2022-11-04"><span class="mr-2">2022-11-04</span><a href="#2022-11-04" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="can-multi-label-classification-networks-know-what-they-dont-know"><span class="mr-2"><a href="https://openreview.net/forum?id=enKhMfthDFS"><span class="mr-2">Can multi-label classification networks know what they don’t know?</a></span><a href="#can-multi-label-classification-networks-know-what-they-dont-know" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：CMU 等<li>主讲人：L<li>内容：启发于基于能量的OOD判别方法，本文针对多标签分类问题基于能量模型提出一种OOD鉴别指标。</ul><h2 id="2022-10-29"><span class="mr-2">2022-10-29</span><a href="#2022-10-29" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="few-shot-open-set-recognition-by-transformation-consistency"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Jeong_Few-Shot_Open-Set_Recognition_by_Transformation_Consistency_CVPR_2021_paper.pdf"><span class="mr-2">Few-shot Open-set Recognition by Transformation Consistency</a></span><a href="#few-shot-open-set-recognition-by-transformation-consistency" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：CVPR 2021<li>作者：韩国 KAIST<li>主讲人：L<li>内容：提出一种不需要训练集中包含未知样本的小样本开放集识别的方法。这种方法基于一类通过对类别原型进行变换的小样本识别方法，利用这种变换的一致性，通过取代原型的方法比较取代前后的距离来判断是否是unseen样本。</ul><h3 id="a-continual-learning-survey-defying-forgetting-in-classification-tasks"><span class="mr-2"><a href="https://arxiv.org/abs/1909.08383"><span class="mr-2">A continual learning survey: Defying forgetting in classification tasks</a></span><a href="#a-continual-learning-survey-defying-forgetting-in-classification-tasks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：IEEE TPAMI 2021<li>作者：比利时鲁汶大学，西班牙巴塞罗那的大学，华为诺亚方舟实验室等<li>主讲人：W<li>内容：</ul><h2 id="2021-10-22"><span class="mr-2">2021-10-22</span><a href="#2021-10-22" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="co2lcontrastive-continual-learning"><span class="mr-2"><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cha_Co2L_Contrastive_Continual_Learning_ICCV_2021_paper.pdf"><span class="mr-2">Co2L：Contrastive Continual Learning</a></span><a href="#co2lcontrastive-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICCV 2021<li>作者：韩国 KAIST<li>主讲人：Z<li>内容：<ul><li>目的：将对比学习用于持续学习中。<li>方法：1.将每个task的交叉熵损失换成监督型对比损失，并提出非对称损失，防止进一步分离之前见过的类（否则会出现存储样本与整体分布的偏差）。2.用instancewise relation distillation防止遗忘。<li>主要结论：对比损失能提取更适合在任务间迁移的特征。</ul></ul><h3 id="exploring-architectural-ingredients-of-adversarially-robust-deep-neural-networks"><span class="mr-2"><a href="https://openreview.net/pdf?id=OdklztJBBYH"><span class="mr-2">Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks</a></span><a href="#exploring-architectural-ingredients-of-adversarially-robust-deep-neural-networks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2021<li>作者：墨尔本大学，北大人工智能学院等<li>主讲人：H<li>内容：在 WRN32-10 的下框架，探究怎样的结构有助于提高神经网络的对抗鲁棒性，发现当越靠近输出层宽度越小时，网络的对抗鲁棒性越强，当越远离输出层的网络参数越大时，对抗鲁棒性越强。</ul><h2 id="2022-10-08"><span class="mr-2">2022-10-08</span><a href="#2022-10-08" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="few-shot-learning-with-part-discovery-and-augmentation-from-unlabeled-images"><span class="mr-2"><a href="https://www.ijcai.org/proceedings/2021/0313.pdf"><span class="mr-2">Few-Shot Learning with Part Discovery and Augmentation from Unlabeled Images</a></span><a href="#few-shot-learning-with-part-discovery-and-augmentation-from-unlabeled-images" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：IJCAI 2021<li>作者：中科大，中科院计算所<li>主讲人：L<li>内容：本文解决的小样本问题场景为：大量的无标签数据可作为特征提取器的预训练数据集。核心思想就是图像中关键Part的获取。在预训练部分，选择每张图像中信息量最大的Part，利用这一Part参与对比学习从而得到下游任务需要的特征提取器。在下游任务中，先用小样本数据训练一个分类器，再用该分类器对无标签数据进行预分类，选择分类概率较高的样本作为增强数据。增强的方法即通过一个样本的attention block，意在放大与类别相关的特征。最后再用增强的数据及原小样本数据重新训练分类器。</ul><h3 id="data-augmentation-for-meta-learning"><span class="mr-2"><a href="https://proceedings.mlr.press/v139/ni21a.html"><span class="mr-2">Data Augmentation for Meta-Learning</a></span><a href="#data-augmentation-for-meta-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICML 2021<li>作者：马里兰大学<li>主讲人：H<li>内容：本文探索了在元学习的不同阶段做数据增广，观察在每个阶段做数据增广的不同表现，得到数据增广在元学习不同阶段所能起到的不同作用</ul><h2 id="2022-09-17"><span class="mr-2">2022-09-17</span><a href="#2022-09-17" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="continual-learning-in-the-teacher-student-setup-impact-of-task-similarity"><span class="mr-2"><a href="http://proceedings.mlr.press/v139/lee21e/lee21e.pdf"><span class="mr-2">Continual Learning in the Teacher-Student Setup: Impact of Task Similarity</a></span><a href="#continual-learning-in-the-teacher-student-setup-impact-of-task-similarity" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICML 2021<li>作者：帝国理工大学，牛津大学等<li>主讲人：Z<li>内容：<ul><li>目的：实验观察持续学习中前后任务的相似性对结果的影响。仅涉及两层神经网络两个任务的情况。<li>方法：teacher-student setup，ODE数值模拟。<li>主要结论：intermediate task similarity leads to greatest forgetting</ul></ul><h3 id="持续且无遗忘的深度学习方法研究"><span class="mr-2">持续且无遗忘的深度学习方法研究</span><a href="#持续且无遗忘的深度学习方法研究" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：博士学位论文<li>作者：胡文鹏（北大数院信息系）<li>主讲人：W<li>内容：<ul><li>目的：通过持续学习克服灾难性遗忘问题，从表面原因（训练样本分布不均衡）与根本原因（特征偏置）下手<li>本次主要汇报第3部分：<ul><li>1.参数生成与模型自适应方法（PGMA）：一种持续学习算法，针对表面原因<li>2.全面学习（HL）：解决单类别分类，用全面正则项（H-reg）实现，解决根本原因<li>3.全面持续学习框架：一种持续学习算法，结合H-reg，引入参数迁移、后处理机制，解决根本原因</ul></ul></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E7%A7%91%E7%A0%94/'>科研</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E6%97%A5%E5%B8%B8%E7%AE%A1%E7%90%86/" class="post-tag no-text-decoration" >日常管理</a> <a href="/tags/%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0/" class="post-tag no-text-decoration" >长期更新</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权，转载请注明</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="http://service.weibo.com/share/share.php?title=组会论文/报告列表（长期更新） - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/paperlist_group-meeting/" data-toggle="tooltip" data-placement="top" title="Weibo" target="_blank" rel="noopener" aria-label="Weibo"> <i class="fa-fw fab fa-weibo"></i> </a> <a href="https://twitter.com/intent/tweet?text=组会论文/报告列表（长期更新） - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/paperlist_group-meeting/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=组会论文/报告列表（长期更新） - Shawn Wang&amp;u=https://pengxiang-wang.github.io/posts/paperlist_group-meeting/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/accordion_transcribed_March-of-Steel-Torrent/">编配：《钢铁洪流进行曲》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Baikal-Lake/">编配：《贝加尔湖畔》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Por-una-Cabeza/">编配：《一步之遥》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Katyusha/">编配：《喀秋莎》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Miyazaki-Hayao-Movie-Themes/">编配：宫崎骏电影主题曲，手风琴二重奏</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/my_bookmarks/"><div class="card-body"> <em class="timeago small" data-ts="1653148800" > 2022-05-22 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>我使用的网站推荐</h3><div class="text-muted small"><p> 看了其他博主的博客，发现很多写过博文分享过自己平时使用的网站，那我也来写一个吧。我只想分享一些自己体验过的、感觉好的，可能不被人熟知的，就不列那些软文里凑数的了。 搜书网站：Library Genesis，Z-library 链接：https://libgen.is, https://z-lib.org 号称是世界上最大的电子书网站，后者是前者的镜像网站，主要用前者就行。基本什么书都能...</p></div></div></a></div><div class="card"> <a href="/posts/my_songbook_project/"><div class="card-body"> <em class="timeago small" data-ts="1676563200" > 2023-02-17 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>我的 Songbook 项目（长期更新）</h3><div class="text-muted small"><p> 我的 songbook 链接如下： Songbook PDF 版：https://pengxiang-wang.github.io/my-songbook/output/songbook.pdf Songbook HTML 版：https://pengxiang-wang.github.io/my-songbook/output/songbook.html GitHub 项目：...</p></div></div></a></div><div class="card"> <a href="/posts/accordion_sheet_music_list/"><div class="card-body"> <em class="timeago small" data-ts="1651766400" > 2022-05-06 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>乐谱汇总：我拉过的手风琴曲（长期更新）</h3><div class="text-muted small"><p> 本文列举了我拉过的手风琴曲，方便个人翻阅。我将将按照我的这篇文章乐曲风格的类别整理。有一些乐谱来源未知，但我尽可能附上乐谱来源。如无说明，均为手风琴独奏。 所有乐谱均可在我的 GitHub 仓库 pengxiang-wang/accordion-sheet-music 下载。 流行音乐 已练熟： He’s a Pirate（电影《加勒比海盗》主题曲）：来自[风流先森]，演奏视频 ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/accordion_transcribed_Katyusha/" class="btn btn-outline-primary" prompt="上一篇"><p>编配：《喀秋莎》手风琴独奏</p></a> <a href="/posts/papernotes_Queried-Unlabeled-Data-Improves-and-Robustifies-Class-Incremental-Learning/" class="btn btn-outline-primary" prompt="下一篇"><p>论文笔记：Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "pengxiang-wang/pengxiang-wang.github.io", "data-repo-id": "R_kgDOHJZRFQ", "data-category": "Announcements", "data-category-id": "DIC_kwDOHJZRFc4COm2c", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "zh-CN", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/pengxiang-wang">Shawn Wang</a>.</p></div><div class="footer-right"><p class="mb-0"> KEEP CALM & CARRY ON</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh-cn.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-H7GH1F7FH5"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-H7GH1F7FH5'); }); </script>
