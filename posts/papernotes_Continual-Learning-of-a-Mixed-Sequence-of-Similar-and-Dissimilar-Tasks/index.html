<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="zh-cn"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="论文信息" /><meta property="og:description" content="论文信息" /><link rel="canonical" href="https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/" /><meta property="og:url" content="https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/" /><meta property="og:site_name" content="Shawn Wang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-07-06T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-03-01T22:12:22+08:00","datePublished":"2022-07-06T00:00:00+08:00","description":"论文信息","headline":"论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks","mainEntityOfPage":{"@type":"WebPage","@id":"https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/"},"url":"https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/"}</script><title>论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks | Shawn Wang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Shawn Wang"><meta name="application-name" content="Shawn Wang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/avatar.jpg " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Shawn Wang</a></div><div class="site-subtitle font-italic">WPX 的个人主页</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>时间表</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于本站</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pengxiang-wang" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://space.bilibili.com/88684674" aria-label="bilibili" target="_blank" rel="noopener"> <i class="fas fa-tv"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shawn.pxwang','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://github.com/pengxiang-wang">Shawn Wang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1657036800" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-07-06 </em> </span> <span> 更新于 <em class="timeago" data-ts="1677679942" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-03-01 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3025 字"> <em>16 分钟</em>阅读</span></div></div></div><div class="post-content"><h2 id="论文信息"><span class="mr-2">论文信息</span><a href="#论文信息" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="continual-learning-of-a-mixed-sequence-of-similar-and-dissimilar-tasks"><span class="mr-2"><a href="https://proceedings.neurips.cc/paper/2020/file/d7488039246a405baf6a7cbc3613a56f-Paper.pdf"><span class="mr-2">Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</a></span><a href="#continual-learning-of-a-mixed-sequence-of-similar-and-dissimilar-tasks" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：NIPS 2020<li>作者：<ul><li><a href="https://underline.io/speakers/97701-zixuan-ke">Zixuan Ke</a>：伊利诺伊大学芝加哥分校，博士生，后者的学生。<li><a href="https://www.cs.uic.edu/~liub/">Bing Liu</a>：伊利诺伊大学芝加哥分校，教授。他是《终身机器学习》的作者，我有系列<a href="https://pengxiang-wang.github.io/tags/终身机器学习/">读书笔记</a>。<li><a href="https://people.mpi-inf.mpg.de/~xhuang/">Xingchang Huang</a>：苏黎世联邦理工大学，博士生。</ul></ul><hr /><h1 id="一场景">一、场景</h1><p>本文的场景就是普通的持续学习，但与其他文章不同的是，其他文章通常只关注如何解决灾难性遗忘，本文认为除了解决灾难性遗忘，还有很多其他的事情要做。</p><p>假设已学完任务 \(1, \cdots, t-1\)，准备学 \(t\)。以作者的理解，对旧任务 \(t_{old}\) 的处理是有区别的：</p><ul><li>如果 \(t_{old}\) 与 \(t\) 相似，则二者的知识应相互<strong>迁移</strong>：<ul><li><strong>前向迁移</strong>（Forward Transfer）：用 \(t_{old}\) 学到的知识帮助新任务 \(t\)；<li><strong>后向迁移</strong>（Backward Transfer）：\(t\) 学到的知识反过来更新旧任务；</ul><li>如果 \(t_{old}\) 与 \(t\) 不相似，则二者蕴含的知识也是不交叉的，所以都应该记住，即在学习新任务 \(t\) 时<strong>避免遗忘</strong> \(t_{old}\) 的知识。</ul><p>而其他文章将其一视同仁，都化为第二种情况，干脆都别忘了。</p><p>迁移学习要求两个领域有相似性（见<a href="https://pengxiang-wang.github.io/posts/readingnotes_Lifelong-Machine-Learning_Chap2/">《终身机器学习》第二章笔记</a>），作者如此分成<strong>相似与不相似的任务</strong>，前者应用迁移学习，所以本文是一篇典型的<strong>持续学习与迁移学习结合</strong>的文章。</p><p>如果任务 \(1,\cdots, t-1\) 都属于作者描述的不相似的任务，那么作者的方法就相当于其他文章了。所以本文也可以看作普通持续学习场景的推广：普通场景任务各不相似，而本文允许 “Mixed Sequence of Similar and Dissimilar Tasks”。</p><p>注意本文的场景必须是<strong>任务增量</strong>（文中称 Task Continual Learning, TCL），任务标识 \(t\) 随数据一并给出。类别增量一般每次来的是不同的类，因此很少会出现相似的情况。</p><h1 id="二模型">二、模型</h1><p>本文模型称为 <strong>CAT</strong>（Continual learning with forgetting Avoidance and knowledge Transfer）。它由三部分组成：</p><ul><li><strong>知识库（KB）</strong>：是一个网络，权重中存储知识，是模型的主要部分。输入即原始输入 \(x\)，输出为 \(x\) 的一个 Embedding，其后可接分类器分类。 记号：\(k_l\) 为第 \(l\) 层神经元个数，\(w_l\) 表示第 \(l\) 层到第 \(l+1\) 层的连接权重；\(g_l\) 表示损失函数在权重 \(w_l\) 上的梯度，二者都是 \(k_l \times k_{l+1}\) 矩阵；\(h_l\) 表示一个输入 \(x\) 在第 \(l\) 层的输出，是 \(k_l\) 维向量。<li><strong>任务 Mask（TM）</strong>：为 KB 网络每一层神经元（不是权重）提供 mask，标识了对当前任务的重要程度，它是二值的 0,1。 记号：\(m_l^{(t)}\) 表示任务 \(t\) 第 \(l\) 层的 mask，是 \(k_l\) 维向量。它起到了选择子网络的作用，注意有时我们想要整个网络，则不允许它起作用（或全设为1）。具体的选择作用表现在两个方面：<ul><li>选择每一层的输出：一个输入 \(x\) 在通过网络得到 \(h_l\) 后，还要调整 \(h_l \otimes = m_l\)（效果是把一些输出值置为0），才能继续通过下一层；（最终，加了 mask 后最后一层的输出可看成针对任务 \(t\) 的特征）<li>选择更新的权重：选择了输出后，未被选中的神经元后面连接的权重就不必更新了。做法是先将 mask 向量扩展（与 broadcast 类似）为形状同 \(w_l\) 的 \(k_l \times k_{l+1}\) 矩阵，再调整梯度 \(g_l \otimes = (1-m_l)\)（效果是把置0的神经元后面权重的梯度置为0）。</ul><li><strong>知识迁移 Attention（KTA）</strong>：是一个使用了简单的 Soft Attention 机制的网络，<strong>负责知识迁移</strong>（参考<a href="https://easyai.tech/ai-definition/attention/">此文章</a>），其目的是把相似任务的结果融合并迁移到新任务上。输入为 \(x\) 过任务 \(i_{sim}\) mask 的一系列特征 \(h_{mask}^{(i_{sim})}\)，输出它们的某个线性组合，其后可接分类器分类：</ul>\[h_{K T A}^{(t)}=\sum_{i} a^{\left(i_{s i m}\right)}\left(\left\{h_{m a s k}^{\left(i_{s i m}\right)}\right\} \theta_{v}\right)\]<p>系数即 Attention 得分：</p>\[a^{\left(i_{s i m}\right)}=\operatorname{softmax}\left(\frac{\left(e_{K T A}^{(t)} \theta_{q}\right)\left(\left\{h_{\operatorname{mask}}^{\left(i_{s i m}\right)}\right\} \theta_{k}\right)^{\top}}{\sqrt{d_{k}}}\right)\]<p>参数有公共的 \(\theta_k,\theta_q,\theta_v\) 和 task-specific 的 \(e_{KTA}^{(t)}\)。Attention 机制有参数少的特点，这些参数存储了更多的知识迁移的经验。</p><p><img data-src="/assets/img/CAT_architecture.png" alt="CAT" width="500" data-proofer-ignore></p><p>模型如图所示，主网络为 KB + KTA，TM 是嵌入在 KB 里的一个挂件。该网络在完全不需要知识迁移的时候使用 KB 的 Embedding 后接分类器分类，而需要迁移的时候将 KB 的 Embedding 再通过 KTA 得到进一步的 Embedding 后接分类器分类。</p><blockquote class="prompt-tip"><div><p>由于是任务增量学习，分类问题是几分类是已经知道的，所以分类头的形状是提前固定的。</p></div></blockquote><h2 id="task-embedding"><span class="mr-2">Task Embedding</span><a href="#task-embedding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>每个任务标识 \(t\) 对应一些 Embedding，它不是输入 \(x\) 的 Embedding，称为 Task Embedding。这些 Embedding 提供了“第几个任务”这种信息，是学习出来的，属于 task-specific 的网络参数，在本文中有两类：</p><ul><li>\(e_l^{(t)}\)（合称 \(e^{(t)}\)）：用于生成 KB 第 \(l\) 层的任务 mask \(m_l^{(t)}\)。二者对应关系为 \(m_{l}^{(t)}=\sigma\left(s e_{l}^{(t)}\right)\)（\(s\) 为超参数），大于 0.5 取 1，反之取 0。<li>\(e_{KTA}^{(t)}\)：用于输入给 KTA，辅助计算 Attention 得分，其完成知识迁移。</ul><p>模型输入不只有 \(x\)，还有任务 ID \(t\)，这正是任务增量学习的设定。如上图右下角所示，任务标识\(t\)先生成两种 Task Embedding，箭头分别指向 KB 和 KTA。</p><h1 id="三测试过程">三、测试过程</h1><p>经过 \(T+1\) 个任务的训练，训练过程已训练好如下参数或了解到如下信息：</p><ul><li>\(\theta^{(T)}\)，它包含所有与任务无关的网络参数，如 KB 的权重，KTA 的 \(\theta_k,\theta_q,\theta_v\) 以及两个分类头的权重。在训练时，它们不断更新，只用最后任务 \(T\) 的结果；<li>每个任务与之前任务的相似性判断结果：每个任务都有两个集合 \(\tau_{sim}, \tau_{dis}\) 分别表示相似任务与不相似任务；<li>每个任务 \(t\) 的 Task Embedding \(e^{(t)}\) 和 \(e_{KTA}^{(t)}\)（后者有的可能没有，也不需要，见下节tip），前面说过它们是 task-specific 的参数。</ul><p><strong>测试过程</strong>：新来一个测试数据 \(x\) 及其任务ID \(t\)：</p><ul><li>如果有前面的任务与之相似（\(\tau_{sim}\neq \varnothing\)），则 \(x\) 通过 KB 在 \(\tau_{sim}\) 任务上的 mask 得到一系列特征 \(h_{mask}^{(i_{sim})}\)，让它们过 KTA 和后面的分类头，得到分类结果；<li>如果没有一个相似，则 \(x\) 通过 \(e^{(t)}\) 生成的该任务的 mask，得到最后一层特征 \(h_{mask}^{(t)}\)，再通过 KB 后面的分类头，得到分类结果。</ul><h1 id="四训练过程">四、训练过程</h1><p><img data-src="/assets/img/CAT_TM.png" alt="CAT" width="450" data-proofer-ignore></p><p><strong>任务 0</strong>：直接训练 \(f_{mask}\)，即 KB + TM + 后面的分类头：</p><ul><li>数据：\(D_{train}^{(0)}\)<li>损失函数：\(\frac{1}{N_{0}} \sum_{i=1}^{N_{0}} \mathcal{L}\left(f_{m a s k}\left(x_{i}^{(0)} ; \theta_{m a s k}\right), y_{i}^{(0)}\right)\)<li>训练方式：因为是第一个任务，随机初始化<li>要用的结果：训练得到的 KB + 分类头权重 \(\theta^{(0)}\)，任务 0 的 Task Embedding \(e^{(0)}\)（对应的任务 mask \(m^{(0)}\) 如图右上）</ul><p><strong>任务 1</strong>：首先判断它与任务 0 是否<strong>相似</strong>。做法是比较两个模型 \(f_{\varnothing}, f_{0\rightarrow 1}\) 的效果：</p><p>先训练<strong>参考模型</strong>（Reference Model） \(f_{\varnothing}\)，即对任务 1 从头开始训练的 KB + 后面的分类头：</p><ul><li>数据：\(D_{train}^{(1)}\)<li>损失函数：\(\frac{1}{N_{1}} \sum_{i=1}^{N_{1}} \mathcal{L}\left(f_{\varnothing}\left(x_{i}^{(1)} ; \theta_{\varnothing}\right), y_{i}^{(1)}\right)\)<li>训练方式：单独复制出来一份 KB（之前的 KB 是主要的东西，不能覆盖掉），随机初始化<li>要用的结果：用验证集 \(D_{val}^{(1)}\) 测试效果</ul><p>再训练<strong>迁移模型</strong>（Transfer Model） \(f_{0\rightarrow 1}\)，即参考模型中的 KB 部分不用从头训，直接用针对任务 0 的特征——将训练数据过任务 0 mask 最后一层的输出，只训练后面的分类头。这件事可以等价地看成固定之前训练的任务 0 的 KB + mask：</p><ul><li>数据：\(D_{train}^{(1)}\)<li>损失函数：\(\frac{1}{N_{1}} \sum_{i=1}^{N_{1}} \mathcal{L}\left(f_{0\rightarrow 1}\left(x_{i}^{(1)} ; \theta_{0\rightarrow 1}\right), y_{i}^{(1)}\right)\)<li>训练方式：固定 KB + mask 部分的权重，分类头随机初始化<li>要用的结果：同上</ul><p>如果迁移模型比参考模型效果好，任务 1 用 0 的知识都比它自己努力学习知识要好，那么有充分的理由说 0 里包含了与 1 相似的知识。相似与否，决定了任务 1 该如何训练：</p><p>若任务 1 与任务 0 不相似，则应该走防止遗忘的路线。先用任务 0 的 mask 屏蔽掉对任务 0 重要的权重，训练任务 1：</p><ul><li>数据：\(D_{train}^{(1)}\)<li>损失函数：\(\frac{1}{N_{1}} \sum_{i=1}^{N_{1}} \mathcal{L}\left(f_{\varnothing}\left(x_{i}^{(1)} ; \theta_{\varnothing}\right), y_{i}^{(1)}\right)\)<li>训练方式：固定 KB 属于任务 0 mask 对应的权重，训练其他部分<li>要用的结果：\(\theta^{(1)}\)，\(e^{(1)}\)（此时任务 mask 如图右中，注意 \(m^{(1)}\) 与 \(m^{(0)}\) 不可能重合）</ul><p>若任务 1 与任务 0 相似，则应该走知识迁移的路线。与迁移模型道理一样，也是提取任务 0 mask 最后一层输出，但这时要训练不是简单的分类头，而是作者提出的专门负责知识迁移的 KTA + 分类头。另一个不同的是，作者没有固定前面的 KTA + TM，它允许被梯度回传训练，一是为了得到 \(e^{(1)}\)（这一步必须有，否则后面任务无法进行）；二是也更新 KB，被认为是 Backward Transfer。</p><ul><li>数据：\(D_{train}^{(1)}\)<li>损失函数：两部分 \(\frac{1}{N_{1}} \sum_{j=1}^{N_{1}} \mathcal{L}\left(f_{m a s k}\left(x_{j}^{(1)} ; \theta_{m a s k}\right), y_{j}^{(1)}\right)+\frac{1}{N_{1}} \sum_{j=1}^{N_{1}} \mathcal{L}\left(f_{K T A}\left(x_{j}^{(1)} ; \theta_{K T A}\right), y_{j}^{(1)}\right)\)<li>训练方式：不要屏蔽任务 0。在 $$正常训练即可<li>要用的结果：\(\theta^{(1)}\)，\(\theta^，\)e^{(1)}\(（此时\)m^{(1)}\(与\)m^{(0)}\(可以有重合，因为任务 0,1 是相似的），\)e_{KTA}^{(1)}$$</ul><p><strong>任务 t</strong>：相当于把任务 1 的两种情况推广到一次面对多个旧任务的情形。</p><p>首先是判断任务相似。此时要比较任务 \(t\) 与 \(0,1,\cdots,t-1\) 共 \(t\) 个任务的相似性。参考模型 \(f_{\varnothing}\)只需要一个，迁移模型则要 \(t\) 个：\(f_{0\rightarrow t}, \cdots, f_{t-1\rightarrow t}\)。得到与 \(t\) 相似与不相似的任务集 \(\tau_{sim}, \tau_{dis}\)。</p><p>对 \(\tau_{dis}\) 中的任务，要防止遗忘，它们重要的权重要统统屏蔽掉，只需要将它们的 mask 并起来即可</p>\[m_{l}^{\left(t_{a c}\right)}=\text { ElementMax }\left(\left\{m_{l}^{\left(i_{d i s}\right)}\right\}\right)\]<p>对 \(\tau_{sim}\) 中的任务，要知识迁移，提取在这些任务 mask 最后一层输出，这可能涉及到多个。所幸这个 KTA 能接受多个输入，也能训练出多个 \(e^{KTA}\)。</p><p>所以，任务 t 要训练的是：</p><ul><li>数据：\(D_{train}^{(t)}\)<li>损失函数：两部分 \(\frac{1}{N_{t}} \sum_{j=1}^{N_{t}} \mathcal{L}\left(f_{m a s k}\left(x_{j}^{(t)} ; \theta_{m a s k}\right), y_{j}^{(t)}\right)+\frac{1}{N_{t}} \sum_{j=1}^{N_{t}} \mathcal{L}\left(f_{K T A}\left(x_{j}^{(t)} ; \theta_{K T A}\right), y_{j}^{(t)}\right)\)<li>训练方式：屏蔽任务 \(\tau_{dis}\)，其他正常训练即可<li>要用的结果：\(\theta^{(t)}\)，\(e^{(t)}\)，\(e_{KTA}^{(t)}\)</ul><blockquote class="prompt-tip"><div><p>请注意，\(e_{KTA}^{(t)}\) 并不是所有任务都需要。如果永远没有与 \(t\) 相似的任务，那么也就无需训练它了，因为测试阶段不可能用到它。</p></div></blockquote><p>上图最下面的两图，表示任务 2，\(\tau_{sim} = \{1\}, \tau_{dis} = \{0\}\)。请自行体会。</p><p>总结一下上面，任务 0 相当于不与前面任何相似。任务 1 由于前面只有一个，要么空集，要么全集；中间情况只有任务 2 才可能开始有。任务 0 和 1 的过程都可以统一到任务 t 的流程内。</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E7%A7%91%E7%A0%94/'>科研</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="post-tag no-text-decoration" >论文笔记</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >机器学习</a> <a href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >持续学习</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权，转载请注明</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="http://service.weibo.com/share/share.php?title=论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/" data-toggle="tooltip" data-placement="top" title="Weibo" target="_blank" rel="noopener" aria-label="Weibo"> <i class="fa-fw fab fa-weibo"></i> </a> <a href="https://twitter.com/intent/tweet?text=论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=论文笔记：Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks - Shawn Wang&amp;u=https://pengxiang-wang.github.io/posts/papernotes_Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/accordion_transcribed_March-of-Steel-Torrent/">编配：《钢铁洪流进行曲》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Baikal-Lake/">编配：《贝加尔湖畔》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Por-una-Cabeza/">编配：《一步之遥》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Katyusha/">编配：《喀秋莎》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Miyazaki-Hayao-Movie-Themes/">编配：宫崎骏电影主题曲，手风琴二重奏</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/papernotes_Queried-Unlabeled-Data-Improves-and-Robustifies-Class-Incremental-Learning/"><div class="card-body"> <em class="timeago small" data-ts="1663862400" > 2022-09-23 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>论文笔记：Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning</h3><div class="text-muted small"><p> 论文信息 Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning 期刊：TMLR 2022 作者：德州大学奥斯汀分校等 本文在类别增量（CIL）场景的简单模型 LwF 基础上做了改进，并使用了三个机制，提升了模型的效果：无标签查询数据（QUD）、辅助分类器平衡训练、对抗样本训练...</p></div></div></a></div><div class="card"> <a href="/posts/papernotes_continual_learning_fast_and_slow/"><div class="card-body"> <em class="timeago small" data-ts="1667491200" > 2022-11-04 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>快慢网络式持续学习</h3><div class="text-muted small"><p> 本文介绍快慢网络式持续学习，即构建一个两部分的网络，慢网络负责粗略特征的学习，快网络负责任务特定的细节特征的学习。它们适用于 TIL、CIL 场景不限。它们都借鉴自神经科学中的互补学习系统（complementary learning systems, CLS）理论。 快慢网络一般要利用人为的规定来区分开，通常是规定训练方式，让二者的训练速度有差别：即让一个学得快，另一个学得慢。 论文信...</p></div></div></a></div><div class="card"> <a href="/posts/papernotes_continual_learning_using_training_info/"><div class="card-body"> <em class="timeago small" data-ts="1668441600" > 2022-11-15 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>使用训练信息的持续学习</h3><div class="text-muted small"><p> 有一类持续学习方法的想法是从旧任务的训练过程中获取信息，存放在记忆中，作为新任务防遗忘的参考。本文统一介绍这种思路。这类方法是为了防止遗忘，属于防遗忘机制的另一种分类法。 此类方法的两要素： 有哪些训练信息可以利用？ 获得的训练信息如何使用？ 下面依次讨论，并给出几篇论文使用的例子。 训练信息 我所谓的训练信息是指随训练过程得到的中间产物，而不是原始的训练数据等信息。这...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cooking_basics/" class="btn btn-outline-primary" prompt="上一篇"><p>一个新手写的做饭基础知识指南</p></a> <a href="/posts/continual_learning/" class="btn btn-outline-primary" prompt="下一篇"><p>持续学习基础知识</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "pengxiang-wang/pengxiang-wang.github.io", "data-repo-id": "R_kgDOHJZRFQ", "data-category": "Announcements", "data-category-id": "DIC_kwDOHJZRFc4COm2c", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "zh-CN", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/pengxiang-wang">Shawn Wang</a>.</p></div><div class="footer-right"><p class="mb-0"> KEEP CALM & CARRY ON</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh-cn.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-H7GH1F7FH5"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-H7GH1F7FH5'); }); </script>
