<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="zh-cn"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="论文笔记：无监督持续学习论文一篇" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="论文信息" /><meta property="og:description" content="论文信息" /><link rel="canonical" href="https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/" /><meta property="og:url" content="https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/" /><meta property="og:site_name" content="Shawn Wang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-04-12T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="论文笔记：无监督持续学习论文一篇" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-03-01T22:12:22+08:00","datePublished":"2022-04-12T00:00:00+08:00","description":"论文信息","headline":"论文笔记：无监督持续学习论文一篇","mainEntityOfPage":{"@type":"WebPage","@id":"https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/"},"url":"https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/"}</script><title>论文笔记：无监督持续学习论文一篇 | Shawn Wang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Shawn Wang"><meta name="application-name" content="Shawn Wang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/avatar.jpg " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Shawn Wang</a></div><div class="site-subtitle font-italic">WPX 的个人主页</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>时间表</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于本站</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pengxiang-wang" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://space.bilibili.com/88684674" aria-label="bilibili" target="_blank" rel="noopener"> <i class="fas fa-tv"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shawn.pxwang','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>论文笔记：无监督持续学习论文一篇</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>论文笔记：无监督持续学习论文一篇</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://github.com/pengxiang-wang">Shawn Wang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1649692800" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-04-12 </em> </span> <span> 更新于 <em class="timeago" data-ts="1677679942" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-03-01 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2694 字"> <em>14 分钟</em>阅读</span></div></div></div><div class="post-content"><h1 id="论文信息">论文信息</h1><h3 id="representational-continuity-for-unsupervised-continual-learning"><span class="mr-2"><a href="https://openreview.net/forum?id=9Hrka5PA7LW"><span class="mr-2">Representational Continuity for Unsupervised Continual Learning</a></span><a href="#representational-continuity-for-unsupervised-continual-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>会议：ICLR 2022 (Oral)<li>作者：<ul><li>纽约大学、韩国科学院、清华大学智能产业研究院等</ul></ul><hr /><h1 id="一场景无监督持续学习">一、场景：无监督持续学习</h1><p>设持续学习包含 $T$ 个任务，当前正在学习第 $\tau$ 个任务。持续学习要求不仅对新数据做Fine-tuning，还要复习过去的知识，这两部分体现在优化目标 $\mathcal{L}$ 的两项，记为</p>\[\mathcal{L} = \mathcal{L}^{\text{FINETUNE}} + \mathcal{L}^{\text{REVIEW}}\]<p>我用一张表来比较有监督和无监督的区别（以分类为例）：</p><div class="table-wrapper"><table><thead><tr><th style="text-align: center"> <th style="text-align: center">有监督持续学习（Supervised CL）<th style="text-align: center">无监督持续学习（Unsupervised CL）<tbody><tr><td style="text-align: center">新来的数据<td style="text-align: center">\(\mathcal{D}_{\tau} = \{(\mathbf{x}_{i,\tau}, y_{i,\tau})_{i=1}^{n_\tau}\}\)<td style="text-align: center">\(\mathcal{U}_\tau = \{(\mathbf{x}_{i,\tau})_{i=1}^{n_\tau}\}\)<tr><td style="text-align: center">模型与参数<td style="text-align: center">\(X_\tau \rightarrow \mathcal{Y}_\tau\)，可看成 表示函数 \(f_\Theta : X_\tau \rightarrow \mathbb{R}^D\) <br />和 分类器 \(h_\psi: \mathbb{R}^D \rightarrow \mathcal{Y}_\tau\)<td style="text-align: center">只有表示 \(f_\Theta : X_\tau \rightarrow \mathbb{R}^D\)<tr><td style="text-align: center">\(\mathcal{L}^{\text{FINETUNE}}\)<td style="text-align: center">\(\mathcal{L}_{\text{SCL}}^{\text{FINETUNE}} = CE(h_\psi(f_\Theta(\mathbf{x}_{i,\tau})，y_{i,\tau})\)<td style="text-align: center"><font color="red"> $$\mathcal{L}_{\text{UCL}}^{\text{FINETUNE}}$$ </font><tr><td style="text-align: center">\(\mathcal{L}^{\text{REVIEW}}\)<td style="text-align: center">由现有的各种持续学习框架定义<td style="text-align: center"><font color="red"> $$\mathcal{L}_{\text{UCL}}^{\text{REVIEW}}$$ </font></table></div><p>对于不同的任务有不同的分类器（注意：$h_\psi(\cdot, \tau)$），分类器是一个比表示$f_\Theta$简单得多的网络，对每个任务 $\tau$ 都会根据当前的 $f_\Theta$ 作微调。虽然这里是有参数的，但完全可以是无参数的，如K近邻分类器。这个分类器不是持续学习的学习目标，只是模型里的一个必要的输出头。</p><p>无论有监督还是无监督，都是为了学到一个好的表示 $f_\theta$ ，但由于有监督的任务要求输出类别 $\mathcal{Y}_\tau$，不可避免地需要接一个分类器。无监督的任务虽然只需要得到表示即可，但是我们无法评估这个表示的好坏，因此一般的评估方法也是接一个分类器，以输出结果与真实类别的比较作为衡量标准，计算准确率等评价指标。这里真实类别的标签只用在评估时，没有用在训练时，损失是一种自监督的损失（self- supervised loss），这是有监督和无监督的本质区别。</p><p>设计 \(\mathcal{L}_{\text{UCL}}^{\text{FINETUNE}}\) 和 \(\mathcal{L}_{\text{UCL}}^{\text{REVIEW}}\)是设计无监督学习框架的主要任务，分别放在第二、第三部分讲述。</p><h1 id="二无监督模型">二、无监督模型</h1><p>目前大火的无监督表示学习模型就是<strong>对比学习</strong>（Contrastive Learning）了，作者选用了其中一些比较适合的持续学习场景的模型，它们都是基于孪生网络的思想。</p><p><strong>孪生网络</strong>（Siamese Network）是要求两个输入的网络，通过网络后分别得到这两个输入的表示。它可以看成一个网络，也可以看成两个共享权重的网络（所以叫孪生网络）。得到的两个表示一般要算一下相似度（最简单的是余弦相似度，即两个向量的夹角），这个相似度用来构造损失，具体什么样的损失由网络要完成的任务来定。任务只有一个要求——<em>两个输入</em>，比如判断两个图片是否是同一类，等等。</p><p><img data-src="/assets/img/siamese_network.png" alt="Siamese" width="500" data-proofer-ignore></p><p>孪生网络如何用在无监督学习中呢？自然，对于一个输入 $\mathbf{x}$，无监督学习要学的表示函数就是这个孪生网络。但是它要求两个输入怎么办呢，接下来就是主要思想：这两个输入是原始输入的两个Augmentation $\mathbf{x}^1,\mathbf{x}^2$，如果这个表示认为由同一个输入 $\mathbf{x}$ 变换出来的 $\mathbf{x}^1,\mathbf{x}^2$ 是相似的，那它就是一个好的表示。因此优化目标是尽量让得到的两个表示接近，构造的损失函数也就用到了上文提到的相似度，一般来说是迫使相似度尽量大，例如</p>\[\mathcal{L} = - D(z_1, z_2)\]<p>其中 $z_1, z_2$ 是 $\mathbf{x}^1,\mathbf{x}^2$ 通过孪生网络 $f$ 后的两个表示，$D$ 是余弦相似度。</p><h2 id="simsiam"><span class="mr-2">SimSiam</span><a href="#simsiam" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/assets/img/SimSiam.png" alt="Siamese" width="400" data-proofer-ignore></p><p>对于无监督的表示学习，Facebook何恺明、陈鑫磊等人提出了一个简单的孪生网络<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.pdf">SimSiam</a>，但是比上面最简单的还是多了一些东西的：它在表示网络后接了一个预测头 $h$（也是一个网络），这样两个输入就有了四个表示：$z_1 \triangleq f(\mathbf{x}_1), z_1 \triangleq f(\mathbf{x}_1), p_1 \triangleq h(f(\mathbf{x}_1)), p_2 \triangleq h(f(\mathbf{x}_2))$。最终交叉混淆处理相似度：</p>\[\mathcal{L} = \frac12 D(p_1, z_2) + \frac12 D(p_2, z_1)\]<p>这个模型最重要的事情是要求把 $z_1,z_2$ 看作常数，而不是含模型参数的函数（在PyTorch里就是<code class="language-plaintext highlighter-rouge">detach</code>一下），记作 \(\text{stopgrad}\)。统一到本文的符号，写作：</p>\[\mathcal{L}_{\mathrm{UCL}}^{\mathrm{FINETUNE}}=\frac{1}{2} D\left(p_{i, \tau}^{1}, \text {stopgrad}\left(z_{i, \tau}^{2}\right)\right)+\frac{1}{2} D\left(p_{i, \tau}^{2}, \text{stopgrad}\left(z_{i, \tau}^{1}\right)\right)\]<h2 id="barlow-twins"><span class="mr-2">Barlow Twins</span><a href="#barlow-twins" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>为了得到一个好的表示，除了使同一个输入 $\mathbf{x}$ 产生的两个变换表示尽量接近，还可以使不同输入的表示尽量地远（其实这样有可能带来问题，暂且不讨论）。Facebook的另外一些人，包括Yann LeCun提出的<a href="https://proceedings.mlr.press/v139/zbontar21a/zbontar21a.pdf">Barlow Twins</a>，就在损失函数中加了第二项：</p>\[\mathcal{L}_{\mathrm{UCL}}^{\mathrm{FINETUNE}} = \sum_i (1 - \mathcal{C}_{ii})^2 + \lambda \cdot \sum_i \sum_{j\neq i} \mathcal{C}_{ij}^2\]<p>这个损失每次考虑多个输入 $\mathbf{x}^1, \cdots, \mathbf{x}^i, \cdots$，同样地，每个输入 $\mathbf{x}^i$ 都有两个Augmentation $\mathbf{x}^i_1,\mathbf{x}^i_2$，$\mathcal{C}_{ij}$ 就是两个输入不同变换之间的相似度 \(\mathcal{C}_{ij} = \mathcal{D}(z^i_1, z^j_2)\)。这个损失的第一项其实就是上面最简单的相似度损失（累加了多个输入的），第二项的损失给了一个可调的超参数 $\lambda$。</p><h1 id="三如何持续起来">三、如何持续起来？</h1><p>大部分持续学习模型都是针对有监督场景的，难以直接应用到无监督，但有一些确实是可以推广的。作者从三类持续学习模型各取了一个代表：</p><h2 id="重演法der"><span class="mr-2">重演法：DER</span><a href="#重演法der" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>重演法一般要在记忆 $\mathcal{M}$ 里存放重演数据，而有些是连同标签一起存进去，训练新任务时构造进REVIEW损失里去，这样的重演模型就不好推广到无监督。作者找到的<a href="https://proceedings.neurips.cc/paper/2020/file/b704ea2c39778f07c617f6b7ce480e9e-Paper.pdf">DER</a>（Dark Experience Replay）用不着重演数据 $x$ 的标签，而是存旧模型预测的过Softmax之前的logit $p$。防止遗忘的方法是让新模型预测重演数据的logit尽量与存的接近：</p>\[\mathcal{L}_{\mathrm{SCL}}^{\mathrm{DER}}=\mathcal{L}_{\mathrm{SCL}}^{\text {FINETUNE }}+\alpha \cdot \mathbb{E}_{(x, p) \sim \mathcal{M}}\left[\left\|\operatorname{softmax}(p)-\operatorname{softmax}\left(h_{\psi}\left(x_{i, \tau}\right)\right)\right\|_{2}^{2}\right]\]<p>推广到无监督，只需将logit换成网络输出的表示：</p>\[\mathcal{L}_{\mathrm{UCL}}^{\mathrm{DER}}=\mathcal{L}_{\mathrm{UCL}}^{\text {FINETUNE}}+\alpha \cdot \mathbb{E}_{(x) \sim \mathcal{M}}\left[\left\|f_{\Theta_{\tau}}(x)-f_{\Theta}\left(x_{i, \tau}\right)\right\|_{2}^{2}\right]\]<p>其实最经典的iCaRL也可以推广到无监督（它的REVIEW损失是蒸馏损失），但是有点古老了效果已达不到SOTA，所以作者没有用它。</p><h2 id="加正则项法si"><span class="mr-2">加正则项法：SI</span><a href="#加正则项法si" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p><a href="https://arxiv.org/abs/1703.04200">SI</a>（Synaptic Intelligence）是对著名持续学习算法<a href="https://www.pnas.org/doi/10.1073/pnas.1611835114">EWC</a> 的改进，在EWC中，由上一个任务 $\tau-1$ 学习下一个任务 $\tau$ 时，</p>\[\mathcal{L}_{\mathrm{SCL}}^{\mathrm{EWC}}=\mathcal{L}_{\mathrm{SCL}}^{\mathrm{FINETUNE}}+\frac{\lambda}{2} \cdot \sum_{i} F_{i, i}\left(\theta_{i}-\theta_{\tau-1, i}^{*}\right)^{2}\]<p>可见加的REVIEW正则项只与之前任务学到的模型参数有关，不涉及数据的标签信息，SI也是如此。因此有监督损失可以轻易推广到 \(\mathcal{L}_{\mathrm{UCL}}^{\mathrm{SI}}\)。</p><h2 id="网络结构法pnn"><span class="mr-2">网络结构法：PNN</span><a href="#网络结构法pnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>这个方法是对网络结构本身动手脚，在不同的任务阶段，网络结构是不同的，持续并不是通过添加正则项 \(\mathcal{L}^{\text{REVIEW}}\)、而是通过训练新的网络参数实现的。在这个<a href="https://arxiv.org/abs/1606.04671">PNN</a>（Progressive Neural Network）中，每次新任务都会在图中右边多出一列网络出来，冻结原有的权重（虚线），只训练新的权重（实线）。</p><p><img data-src="/assets/img/PNN.png" alt="PNN" width="400" data-proofer-ignore></p><p>对无监督学习，只需将网络改成上节的孪生网络，此图用MLP结构，则孪生网络也用MLP即可。训练时的损失 \(\mathcal{L}_{\mathrm{UCL}}^{\mathrm{PNN}}\)就用上节的无监督损失 \(\mathcal{L}_{\mathrm{UCL}}^{\mathrm{FINETUNE}}\)。</p><h1 id="四mixup技巧">四、Mixup技巧</h1><p>作者也借鉴了Facebook实验室提出的<strong><a href="https://openreview.net/forum?id=r1Ddp1-Rb">Mixup技巧</a></strong>。这是一个比较直观的训练上的trick，即任取两个训练数据作线性组合，得到的这种混合数据（基本上在原始训练数据的周边）也拿去训练。机器学习理论中，用最小化由训练数据集构造的损失这种机制被称为<strong>经验风险最小化</strong>（ERM，Empirical Risk Minimization），现在这种最小化原始训练集的<strong>周边风险最小化</strong>（VRM，Vicinal Risk Minimization）。</p><p>这样做的优点显然是能提高模型的鲁棒性，所以作者拿过来用在了他的无监督损失上，这也是本文的主要创新点吧，取名为<strong>LUMP</strong>（Lifelong Unsupervised Mixup）。具体的用法是在对新数据微调的损失 \(\mathcal{L}_{\text{UCL}}^{\text{FINETUNE}}\) 中，不仅使用新数据 $x_{i,\tau}$，而使用新数据与过去知识（注意：LUMP是对DER的改进，需要记忆重演数据 $\mathcal{M}$）的混合：</p>\[\tilde{x}_{i, \tau}=\lambda x_{i, \tau}+(1-\lambda) x_{j, \mathcal{M}}\]<p>。这样，无监督损失 \(\mathcal{L}_{\text{UCL}}\)不仅在\(\mathcal{L}_{\text{UCL}}^{\text{REVIEW}}\) 中考虑了过去的知识，也在 \(\mathcal{L}_{\text{UCL}}^{\text{FINETUNE}}\) 考虑了。这里也给了可调的超参数 \(\lambda\)，用以trade-off持续学习模型的可塑性与稳定性。</p><h1 id="五实验与结论">五、实验与结论</h1><p>总结一下上面提到的无监督持续学习方法，按照 \(\mathcal{L}_{\text{UCL}}^{\text{FINETUNE}}\) 分有SimSiam、Barlow Twins共2类，按照 \(\mathcal{L}_{\text{UCL}}^{\text{REVIEW}}\) 分有改造成无监督场景的SI、PNN、DER、外加作者针对DER的改进LUMP共4类，所以一共有 \(2\times 4 =8\) 个无监督持续模型。本文的实验是连同有监督的持续学习一起，对这些方法做一个对比。和其他持续学习一样，评价指标有各任务平均准确率 \(A = \frac1T \sum_{\tau=1}^T acc_\tau\) 和 各任务平均遗忘程度 \(F = \frac1{T-1}\sum_{\tau=1}^{T-1} \max_{1\leq t \leq \tau}(acc_t - acc_\tau)\) 。</p><p><img data-src="/assets/img/experiment_Representational-Continuity-for-Unsupervised-Continual-Learning.png" alt="Exp" data-proofer-ignore></p><p>应注意这里有监督和无监督实验的关系是：数据集是相同的，无监督就是直接去掉了有监督数据集的标签。作者的实验居然发现<strong>少了标签信息的无监督学习，效果都比有监督好</strong>！可以看到，在这个实验结果中无监督基本是碾压有监督的，根据我的猜测，可能是因为无监督学习使用了两个Augmentation起了主要作用，很大程度上丰富了训练数据。本文提出的LUMP效果也要高于其他方法，可能也是Mixup技巧引入了更多训练数据导致的。小伙伴们觉得这个实验公平吗？</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E7%A7%91%E7%A0%94/'>科研</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="post-tag no-text-decoration" >论文笔记</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >机器学习</a> <a href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >持续学习</a> <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >无监督学习</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权，转载请注明</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="http://service.weibo.com/share/share.php?title=论文笔记：无监督持续学习论文一篇 - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/" data-toggle="tooltip" data-placement="top" title="Weibo" target="_blank" rel="noopener" aria-label="Weibo"> <i class="fa-fw fab fa-weibo"></i> </a> <a href="https://twitter.com/intent/tweet?text=论文笔记：无监督持续学习论文一篇 - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=论文笔记：无监督持续学习论文一篇 - Shawn Wang&amp;u=https://pengxiang-wang.github.io/posts/papernotes_Representational-Continuity-for-Unsupervised-Continual-Learning/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/accordion_transcribed_March-of-Steel-Torrent/">编配：《钢铁洪流进行曲》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Baikal-Lake/">编配：《贝加尔湖畔》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Por-una-Cabeza/">编配：《一步之遥》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Katyusha/">编配：《喀秋莎》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Miyazaki-Hayao-Movie-Themes/">编配：宫崎骏电影主题曲，手风琴二重奏</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/papernotes_Queried-Unlabeled-Data-Improves-and-Robustifies-Class-Incremental-Learning/"><div class="card-body"> <em class="timeago small" data-ts="1663862400" > 2022-09-23 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>论文笔记：Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning</h3><div class="text-muted small"><p> 论文信息 Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning 期刊：TMLR 2022 作者：德州大学奥斯汀分校等 本文在类别增量（CIL）场景的简单模型 LwF 基础上做了改进，并使用了三个机制，提升了模型的效果：无标签查询数据（QUD）、辅助分类器平衡训练、对抗样本训练...</p></div></div></a></div><div class="card"> <a href="/posts/papernotes_continual_learning_fast_and_slow/"><div class="card-body"> <em class="timeago small" data-ts="1667491200" > 2022-11-04 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>快慢网络式持续学习</h3><div class="text-muted small"><p> 本文介绍快慢网络式持续学习，即构建一个两部分的网络，慢网络负责粗略特征的学习，快网络负责任务特定的细节特征的学习。它们适用于 TIL、CIL 场景不限。它们都借鉴自神经科学中的互补学习系统（complementary learning systems, CLS）理论。 快慢网络一般要利用人为的规定来区分开，通常是规定训练方式，让二者的训练速度有差别：即让一个学得快，另一个学得慢。 论文信...</p></div></div></a></div><div class="card"> <a href="/posts/papernotes_continual_learning_using_training_info/"><div class="card-body"> <em class="timeago small" data-ts="1668441600" > 2022-11-15 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>使用训练信息的持续学习</h3><div class="text-muted small"><p> 有一类持续学习方法的想法是从旧任务的训练过程中获取信息，存放在记忆中，作为新任务防遗忘的参考。本文统一介绍这种思路。这类方法是为了防止遗忘，属于防遗忘机制的另一种分类法。 此类方法的两要素： 有哪些训练信息可以利用？ 获得的训练信息如何使用？ 下面依次讨论，并给出几篇论文使用的例子。 训练信息 我所谓的训练信息是指随训练过程得到的中间产物，而不是原始的训练数据等信息。这...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/building_this_site/" class="btn btn-outline-primary" prompt="上一篇"><p>建站的一路坎坷</p></a> <a href="/posts/accordion_and_me/" class="btn btn-outline-primary" prompt="下一篇"><p>我与手风琴</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "pengxiang-wang/pengxiang-wang.github.io", "data-repo-id": "R_kgDOHJZRFQ", "data-category": "Announcements", "data-category-id": "DIC_kwDOHJZRFc4COm2c", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "zh-CN", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/pengxiang-wang">Shawn Wang</a>.</p></div><div class="footer-right"><p class="mb-0"> KEEP CALM & CARRY ON</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh-cn.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-H7GH1F7FH5"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-H7GH1F7FH5'); }); </script>
