<!DOCTYPE html><html lang="zh-CN" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="prefer-datetime-locale" content="zh-cn"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="PyTorch 学习笔记（五）：计算性能" /><meta property="og:locale" content="zh_CN" /><meta name="description" content="本文介绍 PyTorch 与计算性能有关的代码知识，包括如何使用 GPU、并行计算、多服务器计算等等。本文参考 Dive into Deep Learning (PyTorch 版) 中的以下内容： 5.6 节：GPU； 第 12 章：计算性能；" /><meta property="og:description" content="本文介绍 PyTorch 与计算性能有关的代码知识，包括如何使用 GPU、并行计算、多服务器计算等等。本文参考 Dive into Deep Learning (PyTorch 版) 中的以下内容： 5.6 节：GPU； 第 12 章：计算性能；" /><link rel="canonical" href="https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/" /><meta property="og:url" content="https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/" /><meta property="og:site_name" content="Shawn Wang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-11T00:00:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="PyTorch 学习笔记（五）：计算性能" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-05-27T23:26:31+08:00","datePublished":"2022-02-11T00:00:00+08:00","description":"本文介绍 PyTorch 与计算性能有关的代码知识，包括如何使用 GPU、并行计算、多服务器计算等等。本文参考 Dive into Deep Learning (PyTorch 版) 中的以下内容： 5.6 节：GPU； 第 12 章：计算性能；","headline":"PyTorch 学习笔记（五）：计算性能","mainEntityOfPage":{"@type":"WebPage","@id":"https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/"},"url":"https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/"}</script><title>PyTorch 学习笔记（五）：计算性能 | Shawn Wang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Shawn Wang"><meta name="application-name" content="Shawn Wang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/avatar.jpg " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Shawn Wang</a></div><div class="site-subtitle font-italic">WPX 的个人主页</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>首页</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>分类</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>标签</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>时间表</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>关于本站</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/pengxiang-wang" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://space.bilibili.com/88684674" aria-label="bilibili" target="_blank" rel="noopener"> <i class="fas fa-tv"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['shawn.pxwang','qq.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> 首页 </a> </span> <span>PyTorch 学习笔记（五）：计算性能</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> 文章</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="搜索..."> </span> <span id="search-cancel" >取消</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>PyTorch 学习笔记（五）：计算性能</h1><div class="post-meta text-muted"><div> 作者 <em> <a href="https://github.com/pengxiang-wang">Shawn Wang</a> </em></div><div class="d-flex"><div> <span> 发表于 <em class="timeago" data-ts="1644508800" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-02-11 </em> </span> <span> 更新于 <em class="timeago" data-ts="1685201191" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-05-27 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2648 字"> <em>14 分钟</em>阅读</span></div></div></div><div class="post-content"><p>本文介绍 PyTorch 与计算性能有关的代码知识，包括如何使用 GPU、并行计算、多服务器计算等等。本文参考 <a href="https://d2l.ai">Dive into Deep Learning (PyTorch 版)</a> 中的以下内容：</p><ul><li>5.6 节：GPU；<li>第 12 章：计算性能；</ul><hr /><h1 id="深度学习与-gpu">深度学习与 GPU</h1><p>众所周知，深度学习计算可以使用 GPU，往往能极大提高效率。GPU 用于深度学习时与其他任务不同，它更偏向于关注显存而不是算力（显存至少 8G 以上，见“效率问题”一节），因此也没有一个像桌面级显卡那样的天梯图可供参考。这里列举比较有名的型号：</p><ul><li>Nvidia GeForce 系列：个人电脑显卡，目前到 30 系列，价格万元以下，一般装在个人电脑上，跑一些深度学习程序够用；<li>Nvidia RTX A6000：一般装在服务器上，价格比较昂贵，一块几万元；<li>Nvidia Tesla V100：一般装在服务器上，价格比 A6000 贵；<li>Nvidia Tesla A100：比 V100 更强大，目前成为大公司主流使用的。</ul><p>跑深度学习的设备可以：</p><ul><li>使用自己的电脑：<ul><li>不带 GPU 的电脑（如 MacBook）：没有 GPU 的加持，只用 CPU 跑会跑得很慢；<li>带 GPU 的电脑（如 Windows 游戏本有 Nvidia 的独立显卡的）可以跑得快；</ul><li>使用单台服务器（如组内的服务器）；<li>使用多台服务器（如大公司或机构公用的计算集群），方法见本文最后一节。</ul><h1 id="pytorch-与-cuda">PyTorch 与 CUDA</h1><p>深度学习框架为我们提供了使用 GPU 硬件的高级 API，只需简单的代码即可使用 GPU 作深度学习的计算，甚至无需了解原理。</p><p>这些深度学习框架的高级 API 要与 GPU 打交道，但并不是直接打交道的。与普通的程序一样，通常调用操作系统提供的 SDK，操作系统与底层的 CPU 等硬件直接打交道；GPU 制造商也提供了类似 SDK 的接口，使用 GPU 的程序只需调用这个接口即可。Nvidia 公司的 GPU 提供的接口叫 <strong>CUDA</strong>，PyTorch 使用 GPU 的程序也是调用 CUDA 写的。所以要注意：</p><ol><li>要使用 PyTorch GPU 计算，首先显卡本身要支持 CUDA。这要求至少是 Nvidia 的显卡；<li>要安装好 CUDA 才能使用 PyTorch。CUDA 理论上需要去 Nvidia 官网下载，但是不用担心，一般的机器只要有 Nvidia 的显卡，都是要安装显卡驱动的（否则显卡也没什么用），这个驱动里一般都带着 CUDA。没有 CUDA 的就安装驱动即可，也不用去手动下载。如果要手动安装 CUDA，要查好自己的 GPU 是否支持 CUDA，以及对应的 CUDA 版本。可以见 Nvidia 官方公布的对应列表：<a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a>；<li>CUDA 有很多版本，PyTorch 也为不同 CUDA 版本写了不同的代码，在安装的时候必须指定正确（和机器上的 CUDA 版本一致），否则在实际运行时由于不兼容，会跑不通。安装了 CUDA 的机器，可以直接用命令 <code class="language-plaintext highlighter-rouge">nvidia-smi</code> 查看 CUDA 版本（见下）;<li>PyTorch 版本也要和 CUDA 版本匹配（但不需要很严格），详见：<a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a>。</ol><blockquote class="prompt-info"><div><p>另外提一下，CUDA 是 GPU 完成<strong>通用计算</strong>任务的接口。GPU 一开始只是用来处理图像的，当时的接口只能完成图像处理任务；后来才开发出来其他用处，包括深度学习在内的并行计算，CUDA 就是也能完成这些任务的接口。</p></div></blockquote><p>可以通过 <code class="language-plaintext highlighter-rouge">torch.cuda.is_available()</code> 验证是否配置成功。</p><h1 id="查询与表示计算设备">查询与表示计算设备</h1><p>安装了 CUDA 的，用终端命令 <code class="language-plaintext highlighter-rouge">nvidia-smi</code>（已配置环境变量）可以查看此机器的 GPU 信息，包括名称、型号、显存以及正在占用的程序等。每个计算设备（包括 GPU、CPU）用 <code class="language-plaintext highlighter-rouge">torch.device</code> 对象表示，此类构造接受一个字符串参数，字符串只允许以下几个：</p><ul><li><code class="language-plaintext highlighter-rouge">torch.device('cpu')</code>：表示 CPU；<li><code class="language-plaintext highlighter-rouge">torch.device('cuda:i')</code>：表示第 i 个 GPU（i 是自然数）；<li><code class="language-plaintext highlighter-rouge">torch.device('cuda')</code>：等价于 `torch.device(‘cuda:0’).</ul><blockquote class="prompt-warning"><div><p>CPU 是每台机器都有的，<code class="language-plaintext highlighter-rouge">torch.device('cpu')</code> 对象创建后总是与之绑定的；GPU 不是每台都有，而且可能也不会有多个，但仍然可以创建 <code class="language-plaintext highlighter-rouge">torch.device{'cuda:i'}</code> 对象，只是以后调用它时会报错指示 GPU 不存在。 书中写了两个方便的函数，可以自动查询 GPU，提供了简单的纠错机制，防止出现上述错误。纠错机制是通过一个查询可用 GPU 数量的 API：<code class="language-plaintext highlighter-rouge">torch.cuda.device_count()</code>。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="已复制！"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">try_gpu</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="s">'''如果可用，返回第 i 个 GPU 的设备对象（i 默认为 0）；否则返回 CPU 的设备对象'''</span>
  <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s">'cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">try_all_gpus</span><span class="p">():</span>
  <span class="s">'''返回所有可用 GPU 的设备对象列表；否则返回 CPU 的设备对象（也是列表） '''</span>
  <span class="n">devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s">'cuda:</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s">'</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">device_count</span><span class="p">())]</span>
  <span class="k">return</span> <span class="n">devices</span> <span class="k">if</span> <span class="n">devices</span> <span class="k">else</span> <span class="p">[</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">)]</span>
</pre></table></code></div></div></div></blockquote><h1 id="将-tensor-放到-gpu-上">将 Tensor 放到 GPU 上</h1><p>在没有涉及 GPU 时，PyTorch 所有 Tensor 都是存放在内存里，此内存与 CPU 挂钩，做计算时将其运送到 CPU 中处理。所以使用 GPU 做计算要做的事情很简单：只需<strong>将要用 GPU 计算的 Tensor 放到它的内存（称为显存）里</strong>，计算时自动会运送到 GPU 中处理。</p><p>PyTorch 提供了简单的 API 将 Tensor 从不同计算设备来回转移：</p><ul><li>在创建 Tensor 时只需为创建函数指定参数 <code class="language-plaintext highlighter-rouge">device=</code>，即可在指定设备创建，例：<code class="language-plaintext highlighter-rouge">X = torch.ones(2,3,device=torch.device('cuda')</code>；<li></ul><blockquote class="prompt-info"><div><p>只有同一个计算设备的 Tensor 才能一起计算，在 PyTorch 中如果试图对来自不同设备的 Tensor 做计算，会直接报错。</p></div></blockquote><p>深度学习计算涉及的 Tensor 有：<strong>数据、模型参数</strong>。只要所有的数据和参数都在同一计算设备上，就可以做训练了。</p><ul><li>转移数据：<li>转移模型参数：模型和参数是绑定的，无需把参数从 <code class="language-plaintext highlighter-rouge">nn.Module</code> 对象取出来，PyTorch 的 API 形式上只需转移模型：<code class="language-plaintext highlighter-rouge">net.to(device=torch.device('cuda'))</code></ul><h1 id="效率问题">效率问题</h1><p>以下是一些关于效率的 tips：</p><ol><li>在计算设备间转移 Tensor 时间开销是很大的，甚至比真正做计算都大很多。这也是 PyTorch 对不同设备计算直接报错，而不是尝试隐式转移到同一设备，这是为了防止用户发现不到问题造成大量的时间损失。<li>选择哪个计算设备要根据实际情况而定。有的机器 GPU 性能还不如 CPU，那就不要盲目地用 GPU 计算了。<li>而且在一个深度学习流程内，不是所有计算都放在 GPU 上效率才高。GPU 主要的优势是并行计算以及图像处理，主要是用在训练过程中，前面的预处理可能发挥不到 GPU 的优势。通常在临训练前才将数据转移到 GPU 上，但也有例外，如预处理需要处理图像。转移时机应根据实际情况把握。<li>GPU 在训练过程中优势主要发挥在一个 batch 的矩阵并行运算效率很高，所以 batch_size 开得越大越容易发挥计算上的优势。<li>数据 batch 和模型参数都占用了显存。因此 batch_size 越大占用显存越大，容易出现显存不够用的情况。所以减少显存占用的一种方法是将 batch_size 调小，但会牺牲 GPU 的计算效率；另一种方法是减少模型参数、选用更小的模型。</ol><h1 id="pytorch-并行训练">PyTorch 并行训练</h1><p>上述涉及的都是在一个 GPU 上跑项目。当跑大型项目时，更需要在多个 GPU 上跑项目，甚至在多台机器上的多个 GPU，此时需要用到 PyTorch 并行训练的 API，前者称为 DP（Data Parallel），后者称为 DDP（Distributed Data Parallel）。</p><p>目前我的计算资源不够，暂时用不到，不打算学习总结这一部分。感兴趣的可以自行了解，见 PyTorch Tutorial：<a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">https://pytorch.org/tutorials/intermediate/ddp_tutorial.html</a>。</p><h2 id="附集群中的-gpu"><span class="mr-2">附：集群中的 GPU</span><a href="#附集群中的-gpu" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>使用多台服务器跑深度学习的情况，一般是大公司或机构公用的计算集群，即许多台服务器放在一个机房，它们通过统一的软件调度系统管理和使用。如果要使用，我们必须了解一些基本概念。</p><p>在集群中：</p><ul><li>一个节点（node）表示一台机器；<li>一个节点即一台机器一般有多个 GPU；<li>一个分区（partition）表示一群节点，通常是按照功能等分类。例如我们数学学院的集群分 cpu 和 gpu 两区，cpu 区的节点机器 CPU 性能比较好（为了计算数学专业的同学跑 MATLAB 程序用），gpu 区 GPU 性能比较好（为我们做深度学习、图形学的同学）；公司的集群有的会根据 gpu 的性能来分。</ul><p>集群的调度系统一般会限制用户不能直接登录具体的计算节点，而是先登录一个管理节点。在这个管理节点下，需要向调度系统申请使用计算节点。一般来说，用户需要提交一个申请命令，填写使用几个节点、GPU、多长时间等（一般不能指定使用哪个节点或哪个 GPU，这个是由调度系统分配的，不能我行我素），申请成功后即可以登录到计算节点。调度系统有一个非常厉害的功能就是，申请的计算节点和管理节点实时共用存储，内容是完全一样的，用户的数据只能存放在管理节点，并无需复制到计算节点，这一点要注意。其他关于调度系统的细节请自行查看你使用的集群的文档。</p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E7%A7%91%E7%A0%94/'>科研</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/pytorch/" class="post-tag no-text-decoration" >PyTorch</a> <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-tag no-text-decoration" >读书笔记</a> <a href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >《动手学深度学习》</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-tag no-text-decoration" >机器学习</a> <a href="/tags/%E6%8A%80%E6%9C%AF/" class="post-tag no-text-decoration" >技术</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> 本文由作者按照 <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> 进行授权，转载请注明</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">分享</span> <span class="share-icons"> <a href="http://service.weibo.com/share/share.php?title=PyTorch 学习笔记（五）：计算性能 - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/" data-toggle="tooltip" data-placement="top" title="Weibo" target="_blank" rel="noopener" aria-label="Weibo"> <i class="fa-fw fab fa-weibo"></i> </a> <a href="https://twitter.com/intent/tweet?text=PyTorch 学习笔记（五）：计算性能 - Shawn Wang&amp;url=https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=PyTorch 学习笔记（五）：计算性能 - Shawn Wang&amp;u=https://pengxiang-wang.github.io/posts/studynotes_PyTorch_computing/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="分享链接" data-title-succeed="链接已复制！"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">最近更新</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/accordion_transcribed_March-of-Steel-Torrent/">编配：《钢铁洪流进行曲》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Baikal-Lake/">编配：《贝加尔湖畔》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Por-una-Cabeza/">编配：《一步之遥》手风琴四重奏</a><li><a href="/posts/accordion_transcribed_Katyusha/">编配：《喀秋莎》手风琴独奏</a><li><a href="/posts/accordion_transcribed_Miyazaki-Hayao-Movie-Themes/">编配：宫崎骏电影主题曲，手风琴二重奏</a></ul></div><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">文章内容</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>相关文章</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/studynotes_PyTorch_autograd_and_pipeline/"><div class="card-body"> <em class="timeago small" data-ts="1642780800" > 2022-01-22 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PyTorch 学习笔记（一）：自动微分，简单模型的实现</h3><div class="text-muted small"><p> 本系列博文是我学习深度学习框架的学习笔记。深度学习框架大同小异，只须学习一种的原理，其他的都可以快速上手。我使用的是 PyTorch。笔记将着重强调代码原理、思想的理解，而不是具体的代码。 PyTorch 官方文档：https://pytorch.org/docs/stable/index.html PyTorch 中文文档：https://pytorch-cn.readthed...</p></div></div></a></div><div class="card"> <a href="/posts/studynotes_PyTorch_nnModule/"><div class="card-body"> <em class="timeago small" data-ts="1644249600" > 2022-02-08 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PyTorch 学习笔记（三）：自定义网络结构（nn.Module）</h3><div class="text-muted small"><p> 本文介绍如何自定义模型，即 nn.Module 模块的逻辑与使用方法。由此可以搭建自己的深度网络结构。本文参考 Dive into Deep Learning (PyTorch 版) 中的以下内容： 5.1、5.6 节：层和块，自定义层。 nn.Module 官方文档：https://pytorch.org/docs/stable/generated/torch.nn.Module...</p></div></div></a></div><div class="card"> <a href="/posts/studynotes_PyTorch_Dataset_and_Transform/"><div class="card-body"> <em class="timeago small" data-ts="1642867200" > 2022-01-23 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>PyTorch 学习笔记（二）：自定义数据集，数据预处理</h3><div class="text-muted small"><p> 本文总结 PyTorch 中与数据集以及对它的预处理的知识。知乎的这篇文章讲得不错，言简意赅。也可参考官方教程。 PyTorch 中的数据集都是定义了一个 torch.utils.data.Dataset 类型，数据集都是这个类型的实例。必须这样做，因为后面构造 Dataloader 只接收 Dataset 类型，而整个训练过程都是对 Dataloader 的操作。我们已经在笔记（一）...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/studynotes_PyTorch_Projects/" class="btn btn-outline-primary" prompt="上一篇"><p>PyTorch 学习笔记：工程性知识</p></a> <a href="/posts/studynotes_PyTorch_deep_learning_training/" class="btn btn-outline-primary" prompt="下一篇"><p>PyTorch 学习笔记（四）：深度学习的训练</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "pengxiang-wang/pengxiang-wang.github.io", "data-repo-id": "R_kgDOHJZRFQ", "data-category": "Announcements", "data-category-id": "DIC_kwDOHJZRFc4COm2c", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "zh-CN", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2024 <a href="https://github.com/pengxiang-wang">Shawn Wang</a>.</p></div><div class="footer-right"><p class="mb-0"> KEEP CALM & CARRY ON</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">热门标签</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a> <a class="post-tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a> <a class="post-tag" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a> <a class="post-tag" href="/tags/%E6%89%8B%E9%A3%8E%E7%90%B4/">手风琴</a> <a class="post-tag" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0/">持续学习</a> <a class="post-tag" href="/tags/%E4%B9%90%E8%B0%B1/">乐谱</a> <a class="post-tag" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a> <a class="post-tag" href="/tags/pytorch/">PyTorch</a> <a class="post-tag" href="/tags/%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">《动手学深度学习》</a> <a class="post-tag" href="/tags/%E8%AF%AD%E8%A8%80/">语言</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">搜索结果为空</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh-cn.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-H7GH1F7FH5"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-H7GH1F7FH5'); }); </script>
